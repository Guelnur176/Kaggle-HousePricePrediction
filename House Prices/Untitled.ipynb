{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n",
      "              Total   Percent\n",
      "PoolQC         1453  0.995205\n",
      "MiscFeature    1406  0.963014\n",
      "Alley          1369  0.937671\n",
      "Fence          1179  0.807534\n",
      "FireplaceQu     690  0.472603\n",
      "LotFrontage     259  0.177397\n",
      "GarageCond       81  0.055479\n",
      "GarageType       81  0.055479\n",
      "GarageYrBlt      81  0.055479\n",
      "GarageFinish     81  0.055479\n",
      "GarageQual       81  0.055479\n",
      "BsmtExposure     38  0.026027\n",
      "BsmtFinType2     38  0.026027\n",
      "BsmtFinType1     37  0.025342\n",
      "BsmtCond         37  0.025342\n",
      "BsmtQual         37  0.025342\n",
      "MasVnrArea        8  0.005479\n",
      "MasVnrType        8  0.005479\n",
      "Electrical        1  0.000685\n",
      "Utilities         0  0.000000\n",
      "(1434, 71)\n",
      "(1432, 70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/christian/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape train: (1434, 249)\n",
      "Indice da coluna SalePrice no novo dataset 239\n",
      "New shape test: (1432, 248)\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def remove_categorical_columns(df):\n",
    "    df.drop('MSZoning',axis=1,inplace=True)\n",
    "    df.drop('Street',axis=1,inplace=True)\n",
    "    df.drop('Alley',axis=1,inplace=True)\n",
    "    df.drop('LotShape',axis=1,inplace=True)\n",
    "    df.drop('LandContour',axis=1,inplace=True)\n",
    "    df.drop('Utilities',axis=1,inplace=True)\n",
    "    df.drop('LotConfig',axis=1,inplace=True)\n",
    "    df.drop('LandSlope',axis=1,inplace=True)\n",
    "    df.drop('Neighborhood',axis=1,inplace=True)\n",
    "    df.drop('Condition1',axis=1,inplace=True)\n",
    "    df.drop('Condition2',axis=1,inplace=True)\n",
    "    df.drop('BldgType',axis=1,inplace=True)\n",
    "    df.drop('HouseStyle',axis=1,inplace=True)\n",
    "    df.drop('RoofStyle',axis=1,inplace=True)\n",
    "    df.drop('RoofMatl',axis=1,inplace=True)\n",
    "    df.drop('Exterior1st',axis=1,inplace=True)\n",
    "    df.drop('Exterior2nd',axis=1,inplace=True)\n",
    "    df.drop('MasVnrType',axis=1,inplace=True)\n",
    "    df.drop('ExterQual',axis=1,inplace=True)\n",
    "    df.drop('ExterCond',axis=1,inplace=True)\n",
    "    df.drop('Foundation',axis=1,inplace=True)\n",
    "    df.drop('BsmtQual',axis=1,inplace=True)\n",
    "    df.drop('BsmtCond',axis=1,inplace=True)\n",
    "    df.drop('BsmtExposure',axis=1,inplace=True)\n",
    "    df.drop('BsmtFinType1',axis=1,inplace=True)\n",
    "    df.drop('BsmtFinType2',axis=1,inplace=True)\n",
    "    df.drop('Heating',axis=1,inplace=True)\n",
    "    df.drop('HeatingQC',axis=1,inplace=True)\n",
    "    df.drop('CentralAir',axis=1,inplace=True)\n",
    "    df.drop('Electrical',axis=1,inplace=True)\n",
    "    df.drop('KitchenQual',axis=1,inplace=True)\n",
    "    df.drop('Functional',axis=1,inplace=True)\n",
    "    df.drop('FireplaceQu',axis=1,inplace=True)\n",
    "    df.drop('GarageType',axis=1,inplace=True)\n",
    "    df.drop('GarageFinish',axis=1,inplace=True)\n",
    "    df.drop('GarageQual',axis=1,inplace=True)\n",
    "    df.drop('GarageCond',axis=1,inplace=True)\n",
    "    df.drop('PavedDrive',axis=1,inplace=True)\n",
    "    df.drop('PoolQC',axis=1,inplace=True)\n",
    "    df.drop('Fence',axis=1,inplace=True)\n",
    "    df.drop('MiscFeature',axis=1,inplace=True)\n",
    "    df.drop('SaleType',axis=1,inplace=True)\n",
    "    df.drop('SaleCondition',axis=1,inplace=True)\n",
    "\n",
    "def input_missing_value(df):\n",
    "    \n",
    "    \n",
    "    #LotFrontage - insert the mean \n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=1)\n",
    "    #print(np.shape(df['LotFrontage']))\n",
    "    aux = imp.fit_transform(df['LotFrontage']).transpose()    \n",
    "    #print(np.shape(aux))\n",
    "    df['LotFrontage'] = aux\n",
    "    #print(df['LotFrontage'])\n",
    "\n",
    "    #Alley\n",
    "    df.Alley.fillna(inplace=True,value='No')\n",
    "\n",
    "    #MasVnrType - remove the records where the value is NA\n",
    "    #print(\"Number of lines where MasVnrType has Nan value\", len(df[df['MasVnrType'].isnull()]))\n",
    "    df.dropna(axis=0,subset=['MasVnrType'],inplace=True)\n",
    "    #print(\"Number of lines where MasVnrType has Nan value\",len(df[df['MasVnrType'].isnull()]))\n",
    "\n",
    "    #MasVnrArea - remove the hole column\n",
    "    df.drop('MasVnrArea',axis=1,inplace=True)\n",
    "    \n",
    "    #Condition2 - remove the hole column Possui quantidade de tipos diferentes na base de treino e teste e apenas \n",
    "    #um dos tipos é relevante    \n",
    "    df.drop('Condition2',axis=1,inplace=True)\n",
    "    \n",
    "    #RoofMatl - remove the hole column Possui quantidade de tipos diferentes na base de treino e teste e apenas \n",
    "    #um dos tipos é relevante    \n",
    "    df.drop('RoofMatl',axis=1,inplace=True)\n",
    "    \n",
    "\n",
    "    #MsZoning   - tem NA apenas na base de teste  \n",
    "    df.dropna(axis=0,subset=['MSZoning'],inplace=True)\n",
    "    \n",
    "    #BsmtQual\n",
    "    df.BsmtQual.fillna(inplace=True,value='No')\n",
    "    \n",
    "    #HouseStyle - Esse valor so existe na base de treino. Ao inves de remover toda coluna removo somente as linhas \n",
    "    df.drop(df[df.HouseStyle=='2.5Fin'].index,inplace=True)\n",
    "    \n",
    "    #BsmtCond\n",
    "    df.BsmtCond.fillna(inplace=True,value='No')\n",
    "\n",
    "    #BsmtExposure\n",
    "    df.BsmtExposure.fillna(inplace=True,value='No')\n",
    "\n",
    "    #BsmtFinType1\n",
    "    df.BsmtFinType1.fillna(inplace=True,value='No')\n",
    "\n",
    "    #BsmtFinType2\n",
    "    df.BsmtFinType2.fillna(inplace=True,value='No')\n",
    "\n",
    "    #Electrical - remove the records where the value is NA\n",
    "    #print(\"Number of lines where Electrical has Nan value\",len(df[df['Electrical'].isnull()]))\n",
    "    df.dropna(axis=0,subset=['Electrical'],inplace=True)\n",
    "    df.drop(df[df.Electrical=='Mix'].index,inplace=True)\n",
    "    #print(\"Number of lines where Electrical has Nan value\",len(df[df['Electrical'].isnull()]))\n",
    "\n",
    "    #FireplaceQu\n",
    "    df.FireplaceQu.fillna(inplace=True,value='No')\n",
    "\n",
    "    #GarageType\n",
    "    df.GarageType.fillna(inplace=True,value='No')\n",
    "\n",
    "    #GarageYrBlt - remove the hole column\n",
    "    df.drop('GarageYrBlt',axis=1,inplace=True)\n",
    "\n",
    "    #GarageFinish\n",
    "    df.GarageFinish.fillna(inplace=True,value='No')\n",
    "\n",
    "    #GarageQual - A base de teste nao tem um dos tipos presente na base de treino. Assim a base de treino terá uma \n",
    "    #feature para esse tipo e a de teste não. Alem disso, apenas um tipo é pertinente\n",
    "    #Achei melhor entao excluir essa coluna    \n",
    "    df.drop('GarageQual',axis=1,inplace=True)\n",
    "    #df.drop(df[df.GarageQual=='Ex'].index,inplace=True)\n",
    "    \n",
    "    #GarageCond\n",
    "    df.GarageCond.fillna(inplace=True,value='No')\n",
    "\n",
    "    #PoolQC\n",
    "    #df.PoolQC.fillna(inplace=True,value='No')\n",
    "    df.drop('PoolQC',axis=1,inplace=True)\n",
    "    \n",
    "    #Fence\n",
    "    df.Fence.fillna(inplace=True,value='No')\n",
    "\n",
    "    #MiscFeature\n",
    "    #df.MiscFeature.fillna(inplace=True,value='No')\n",
    "    df.drop('MiscFeature',axis=1,inplace=True)\n",
    "\n",
    "    #MiscVal\n",
    "    df.drop('MiscVal',axis=1,inplace=True)\n",
    "    \n",
    "    #SaleType\n",
    "    df.drop('SaleType',axis=1,inplace=True)\n",
    "    \n",
    "    #Exterior1st\n",
    "    df.dropna(axis=0,subset=['Exterior1st'],inplace=True)\n",
    "    df.drop(df[df.Exterior1st=='Stone'].index,inplace=True)\n",
    "    df.drop(df[df.Exterior1st=='ImStucc'].index,inplace=True)\n",
    "    df.drop(df[df.Exterior1st=='CBlock'].index,inplace=True)\n",
    "\n",
    "    #Exterior2nd\n",
    "    df.dropna(axis=0,subset=['Exterior2nd'],inplace=True)\n",
    "    df.drop(df[df.Exterior2nd=='Other'].index,inplace=True)\n",
    "    df.drop(df[df.Exterior2nd=='CBlock'].index,inplace=True)\n",
    "    \n",
    "    #Heating\n",
    "    df.drop(df[df.Heating=='OthW'].index,inplace=True)\n",
    "    df.drop(df[df.Heating=='Floor'].index,inplace=True)\n",
    "    \n",
    "    #KitchenQual\n",
    "    df.dropna(axis=0,subset=['KitchenQual'],inplace=True)\n",
    "    \n",
    "    #Functional\n",
    "    df.dropna(axis=0,subset=['Functional'],inplace=True)\n",
    "    \n",
    "    #Utilities\n",
    "    df.drop('Utilities',axis=1,inplace=True)\n",
    "    \n",
    "    #BsmtFinSF1\n",
    "    df.dropna(axis=0,subset=['BsmtFinSF1'],inplace=True)\n",
    "    \n",
    "    #BsmtFinSF2\n",
    "    df.dropna(axis=0,subset=['BsmtFinSF2'],inplace=True)\n",
    "    \n",
    "    #BsmtUnfSF\n",
    "    df.dropna(axis=0,subset=['BsmtUnfSF'],inplace=True)\n",
    "    \n",
    "    #TotalBsmtSF\n",
    "    df.dropna(axis=0,subset=['TotalBsmtSF'],inplace=True)\n",
    "    \n",
    "    #BsmtFullBath\n",
    "    df.dropna(axis=0,subset=['BsmtFullBath'],inplace=True)\n",
    "    \n",
    "    #BsmtHalfBath\n",
    "    df.dropna(axis=0,subset=['BsmtHalfBath'],inplace=True)\n",
    "    \n",
    "    #GarageCars\n",
    "    df.dropna(axis=0,subset=['GarageCars'],inplace=True)\n",
    "    \n",
    "    #GarageArea\n",
    "    df.dropna(axis=0,subset=['GarageArea'],inplace=True)\n",
    "    \n",
    "df = pd.read_csv(\"train.csv\",na_values=['?','NA'],delimiter=',',delim_whitespace=False)\n",
    "df_test = pd.read_csv(\"test.csv\",na_values=['?','NA'],delimiter=',',delim_whitespace=False)\n",
    "\n",
    "print(df.shape)\n",
    "print(df_test.shape)\n",
    "#print(df.head())\n",
    "#print(df.describe)\n",
    "#print(df.dtypes)\n",
    "#df = df.dropna()\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "########################Dealing with missing values\n",
    "\n",
    "#missing data\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "print(missing_data.head(20))\n",
    "\n",
    "# \n",
    "#               Total   Percent\n",
    "# PoolQC         1453  0.995205\n",
    "# MiscFeature    1406  0.963014\n",
    "# Alley          1369  0.937671\n",
    "# Fence          1179  0.807534\n",
    "# FireplaceQu     690  0.472603\n",
    "# LotFrontage     259  0.177397\n",
    "# GarageCond       81  0.055479\n",
    "# GarageType       81  0.055479\n",
    "# GarageYrBlt      81  0.055479\n",
    "# GarageFinish     81  0.055479\n",
    "# GarageQual       81  0.055479\n",
    "# BsmtExposure     38  0.026027\n",
    "# BsmtFinType2     38  0.026027\n",
    "# BsmtFinType1     37  0.025342\n",
    "# BsmtCond         37  0.025342\n",
    "# BsmtQual         37  0.025342\n",
    "# MasVnrArea        8  0.005479\n",
    "# MasVnrType        8  0.005479\n",
    "# Electrical        1  0.000685\n",
    "# Utilities         0  0.000000\n",
    "\n",
    "\n",
    "\n",
    "#print(df.columns[df.isnull().any()])\n",
    "#'LotFrontage', 'Alley', 'MasVnrType', 'MasVnrArea', 'BsmtQual',\n",
    "#       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "#       'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
    "#       'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence',\n",
    "#       'MiscFeature'\n",
    "input_missing_value(df)\n",
    "\n",
    "\n",
    "#print(df_test.columns[df_test.isnull().any()])\n",
    "#Index(['MSZoning', 'LotFrontage', 'Alley', 'Utilities', 'Exterior1st',\n",
    "#       'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond',\n",
    "#       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
    "#      'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n",
    "#       'BsmtHalfBath', 'KitchenQual', 'Functional', 'FireplaceQu',\n",
    "#      'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea',\n",
    "#       'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature',\n",
    "#       'SaleType'],\n",
    "\n",
    "input_missing_value(df_test)\n",
    "\n",
    "print(df.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "########################End dealing with missing values\n",
    "\n",
    "########################Tratando campos nominais\n",
    "\n",
    "vec = DictVectorizer()\n",
    "aux = np.asmatrix(vec.fit_transform(df.transpose().to_dict().values()).toarray())\n",
    "\n",
    "#np.savetxt('testfile.csv', aux, delimiter=\",\")\n",
    "#print((vec.feature_names_))\n",
    "#print(np.shape(categorical_columns))\n",
    "#print(categorical_columns)\n",
    "data_train = pd.DataFrame(aux,columns=vec.feature_names_)\n",
    "\n",
    "# The OneHotEncoder converts features represented as numeric codes (so they are values that can't be ordered) to their binary representation\n",
    "#enc = preprocessing.OneHotEncoder() \n",
    "#aux = enc.fit_transform(data_train)\n",
    "\n",
    "data_train.to_csv('train_no_categorical.csv')\n",
    "\n",
    "print(\"New shape train:\" , np.shape(data_train))\n",
    "print(\"Indice da coluna SalePrice no novo dataset\" , data_train.columns.get_loc('SalePrice'))\n",
    "\n",
    "\n",
    "\n",
    "################################################# Base de teste\n",
    "\n",
    "\n",
    "aux_test = vec.fit_transform(df_test.transpose().to_dict().values()).toarray()\n",
    "data_test = pd.DataFrame(aux_test,columns=vec.feature_names_)\n",
    "print(\"New shape test:\" , np.shape(data_test))\n",
    "\n",
    "data_test.to_csv('test_no_categorical.csv')\n",
    "\n",
    "\n",
    "print(data_test.columns.difference(data_train.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tentativa de selecionar melhores features \n",
      "\n",
      "As features selecionadas com Tree-based feature selection foram: \n",
      "\n",
      "   1stFlrSF  2ndFlrSF  3SsnPorch  Alley=Grvl  Alley=No  Alley=Pave  \\\n",
      "0  0.020157  0.007181   0.001113    0.000158  0.000462    0.000216   \n",
      "\n",
      "   BedroomAbvGr  BldgType=1Fam  BldgType=2fmCon  BldgType=Duplex    ...     \\\n",
      "0      0.004442       0.005353         0.000121         0.000116    ...      \n",
      "\n",
      "   SaleCondition=Partial  ScreenPorch  Street=Grvl  Street=Pave  TotRmsAbvGrd  \\\n",
      "0               0.001983     0.000618     0.000128     0.000088      0.014146   \n",
      "\n",
      "   TotalBsmtSF  WoodDeckSF  YearBuilt  YearRemodAdd    YrSold  \n",
      "0     0.012152    0.002962   0.009906      0.004872  0.001668  \n",
      "\n",
      "[1 rows x 248 columns]\n",
      "\n",
      " New shape train apos Tree-based feature selection: (1434, 24)\n",
      "\n",
      " Fim tentativa selecionar melhores features \n",
      "\n",
      "\n",
      " New shape test apos Tree-based feature selection: (1432, 24)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Tentativa de selecionar melhores features \\n\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#Removing features with low variance\n",
    "#print(\"Original shape: {}\".format(np.shape(df.iloc[:,0:-1])))\n",
    "#sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "#features = sel.fit_transform(df.iloc[:,0:-1])\n",
    "#print(\"Shape apos Removing features with low variance {}\".format(np.shape(features))) #nenhuma foi selecionada \n",
    "#print(\"\\n\")\n",
    "\n",
    "#Tree-based feature selection\n",
    "y_train = (data_train['SalePrice'])\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "\n",
    "clf = ExtraTreesRegressor()\n",
    "clf = clf.fit(x_train,y_train)\n",
    "data = np.zeros((1,x_train.shape[1])) \n",
    "data = pd.DataFrame(data, columns=x_train.columns)\n",
    "data.iloc[0] = clf.feature_importances_\n",
    "print(\"As features selecionadas com Tree-based feature selection foram: \\n\")\n",
    "print(data)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "aux = model.transform(x_train)\n",
    "\n",
    "print(\"\\n New shape train apos Tree-based feature selection: {}\".format(aux.shape))\n",
    "\n",
    "print(\"\\n Fim tentativa selecionar melhores features \\n\")\n",
    "\n",
    "\n",
    "data_train_less_features = pd.concat([pd.DataFrame(aux),pd.DataFrame(y_train)],axis=1)\n",
    "data_train_less_features.to_csv('data_train_less_features.csv')\n",
    "\n",
    "\n",
    "aux = model.transform((data_test))\n",
    "data_test_less_features = pd.DataFrame(aux)\n",
    "print(\"\\n New shape test apos Tree-based feature selection: {}\".format(aux.shape))\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn   import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso 1 - Linear Regression \n",
      "Fold #1\n",
      "Fold score (RMSE): 8354563543231763.00\n",
      "Accuracy: -12458030138837715386368.000\n",
      "Fold #2\n",
      "Fold score (RMSE): 158460584181134752.00\n",
      "Accuracy: -3726408452776093298982912.000\n",
      "Fold #3\n",
      "Fold score (RMSE): 113731207645894576.00\n",
      "Accuracy: -1763348002058255906897920.000\n",
      "Fold #4\n",
      "Fold score (RMSE): 31231.60\n",
      "Accuracy: 0.837\n",
      "Fold #5\n",
      "Fold score (RMSE): 332493846203527872.00\n",
      "Accuracy: -20338904494499399144046592.000\n",
      "\n",
      " Average RMSE: 1.7226996583672058e+17\n",
      "Fold #1\n",
      "Fold score (RMSE): 25029.32\n",
      "Accuracy: 0.882\n",
      "Fold #2\n",
      "Fold score (RMSE): 34206.18\n",
      "Accuracy: 0.820\n",
      "Fold #3\n",
      "Fold score (RMSE): 35444.85\n",
      "Accuracy: 0.835\n",
      "Fold #4\n",
      "Fold score (RMSE): 26730.03\n",
      "Accuracy: 0.862\n",
      "Fold #5\n",
      "Fold score (RMSE): 46940.19\n",
      "Accuracy: 0.659\n",
      "\n",
      " Average RMSE: 34546.2696785365\n"
     ]
    }
   ],
   "source": [
    "#Starting making predictors\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Caso 1 - Linear Regression \n",
    "print(\"Caso 1 - Linear Regression \")\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#Normalization\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = LinearRegression()\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# The mean squared error\n",
    "#pred = classifier.predict(x_test_scaled)\n",
    "#score = metrics.mean_squared_error(y_test, pred)\n",
    "#print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "\n",
    "# Evaluate success using accuracy\n",
    "#print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "\n",
    "\n",
    "###########Less features\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "#Normalization\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = LinearRegression()\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Fold #1\n",
      "Fold score (RMSE): 91451.24\n",
      "Accuracy: -0.109\n",
      "Fold #2\n",
      "Fold score (RMSE): 83902.18\n",
      "Accuracy: -0.096\n",
      "Fold #3\n",
      "Fold score (RMSE): 80587.27\n",
      "Accuracy: -0.053\n",
      "Fold #4\n",
      "Fold score (RMSE): 75341.57\n",
      "Accuracy: -0.009\n",
      "Fold #5\n",
      "Fold score (RMSE): 73213.60\n",
      "Accuracy: -0.027\n",
      "\n",
      " Average RMSE: 81164.11977033691\n",
      "\n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 75656.64\n",
      "Accuracy: -0.081\n",
      "Fold #2\n",
      "Fold score (RMSE): 83069.98\n",
      "Accuracy: -0.062\n",
      "Fold #3\n",
      "Fold score (RMSE): 89929.05\n",
      "Accuracy: -0.061\n",
      "Fold #4\n",
      "Fold score (RMSE): 72255.86\n",
      "Accuracy: -0.010\n",
      "Fold #5\n",
      "Fold score (RMSE): 83067.90\n",
      "Accuracy: -0.066\n",
      "\n",
      " Average RMSE: 81033.0859113717\n"
     ]
    }
   ],
   "source": [
    "#Caso 3 - SVM\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "print(\"SVM\")\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#Normalization\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = SVR()\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# The mean squared error\n",
    "#pred = classifier.predict(x_test_scaled)\n",
    "#score = metrics.mean_squared_error(y_test, pred)\n",
    "#print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "\n",
    "# Evaluate success using accuracy\n",
    "#print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "###########Less features\n",
    "print(\"\\n\\n\")\n",
    "#Normalization\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = SVR()\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN MLPRegressor\n",
      "Fold #1\n",
      "Fold score (RMSE): 73086.60\n",
      "Accuracy: -0.006\n",
      "Fold #2\n",
      "Fold score (RMSE): 68428.58\n",
      "Accuracy: -0.025\n",
      "Fold #3\n",
      "Fold score (RMSE): 75633.14\n",
      "Accuracy: -0.000\n",
      "Fold #4\n",
      "Fold score (RMSE): 91359.70\n",
      "Accuracy: -0.000\n",
      "Fold #5\n",
      "Fold score (RMSE): 84445.47\n",
      "Accuracy: -0.004\n",
      "\n",
      " Average RMSE: 79017.76606916856\n",
      "\n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 31801.80\n",
      "Accuracy: 0.809\n",
      "Fold #2\n",
      "Fold score (RMSE): 44070.68\n",
      "Accuracy: 0.701\n",
      "Fold #3\n",
      "Fold score (RMSE): 38829.98\n",
      "Accuracy: 0.802\n",
      "Fold #4\n",
      "Fold score (RMSE): 26362.99\n",
      "Accuracy: 0.866\n",
      "Fold #5\n",
      "Fold score (RMSE): 48646.83\n",
      "Accuracy: 0.634\n",
      "\n",
      " Average RMSE: 38781.083298777296\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Shuffle\n",
    "print(\"NN MLPRegressor\")\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#Normalization\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(18,4,2), random_state=1)\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# The mean squared error\n",
    "#pred = classifier.predict(x_test_scaled)\n",
    "#score = metrics.mean_squared_error(y_test, pred)\n",
    "#print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "\n",
    "# Evaluate success using accuracy\n",
    "#print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "###########Less features\n",
    "print(\"\\n\\n\")\n",
    "#Normalization\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(18,4,2), random_state=1)\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests\n",
      "Mean squared error: 32611.845615538874\n",
      "Accuracy: 0.852\n",
      "\n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 35113.20488624096\n",
      "Accuracy: 0.792\n",
      "Fold #2\n",
      "Fold score (RMSE): 30655.04103661104\n",
      "Accuracy: 0.863\n",
      "Fold #3\n",
      "Fold score (RMSE): 29521.43906865282\n",
      "Accuracy: 0.869\n",
      "Fold #4\n",
      "Fold score (RMSE): 21945.8625031614\n",
      "Accuracy: 0.897\n",
      "Fold #5\n",
      "Fold score (RMSE): 32277.959678505667\n",
      "Accuracy: 0.849\n",
      "\n",
      " Average RMSE: 30223.2498654645\n",
      "\n",
      "\n",
      "\n",
      "Mean squared error: 34097.085261564884\n",
      "Accuracy: 0.838\n",
      "\n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 28500.4921894397\n",
      "Accuracy: 0.847\n",
      "Fold #2\n",
      "Fold score (RMSE): 35753.47811888413\n",
      "Accuracy: 0.803\n",
      "Fold #3\n",
      "Fold score (RMSE): 29770.021202776516\n",
      "Accuracy: 0.884\n",
      "Fold #4\n",
      "Fold score (RMSE): 25137.979859517178\n",
      "Accuracy: 0.878\n",
      "Fold #5\n",
      "Fold score (RMSE): 31883.442369466597\n",
      "Accuracy: 0.843\n",
      "\n",
      " Average RMSE: 30413.800611294148\n"
     ]
    }
   ],
   "source": [
    "##Random Forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Shuffle\n",
    "print(\"Random Forests\")\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_train.drop('SalePrice',axis=1), data_train['SalePrice'], test_size=0.20, random_state=42)\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test,y=y_test))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train.as_matrix()[training]\n",
    "    y_train_fold = y_train.as_matrix()[training]\n",
    "    x_test_fold = x_train.as_matrix()[test]\n",
    "    y_test_fold = y_train.as_matrix()[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# The mean squared error\n",
    "#pred = classifier.predict(x_test_scaled)\n",
    "#score = metrics.mean_squared_error(y_test, pred)\n",
    "#print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "\n",
    "# Evaluate success using accuracy\n",
    "#print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "###########Less features\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_train_less_features.drop('SalePrice',axis=1), \n",
    "                                    data_train_less_features['SalePrice'], test_size=0.20, random_state=42)\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test,y=y_test))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train.as_matrix()[training]\n",
    "    y_train_fold = y_train.as_matrix()[training]\n",
    "    x_test_fold = x_train.as_matrix()[test]\n",
    "    y_test_fold = y_train.as_matrix()[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
