{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n",
      "Id                 int64\n",
      "MSSubClass         int64\n",
      "MSZoning          object\n",
      "LotFrontage      float64\n",
      "LotArea            int64\n",
      "Street            object\n",
      "Alley             object\n",
      "LotShape          object\n",
      "LandContour       object\n",
      "Utilities         object\n",
      "LotConfig         object\n",
      "LandSlope         object\n",
      "Neighborhood      object\n",
      "Condition1        object\n",
      "Condition2        object\n",
      "BldgType          object\n",
      "HouseStyle        object\n",
      "OverallQual        int64\n",
      "OverallCond        int64\n",
      "YearBuilt          int64\n",
      "YearRemodAdd       int64\n",
      "RoofStyle         object\n",
      "RoofMatl          object\n",
      "Exterior1st       object\n",
      "Exterior2nd       object\n",
      "MasVnrType        object\n",
      "MasVnrArea       float64\n",
      "ExterQual         object\n",
      "ExterCond         object\n",
      "Foundation        object\n",
      "                  ...   \n",
      "BedroomAbvGr       int64\n",
      "KitchenAbvGr       int64\n",
      "KitchenQual       object\n",
      "TotRmsAbvGrd       int64\n",
      "Functional        object\n",
      "Fireplaces         int64\n",
      "FireplaceQu       object\n",
      "GarageType        object\n",
      "GarageYrBlt      float64\n",
      "GarageFinish      object\n",
      "GarageCars         int64\n",
      "GarageArea         int64\n",
      "GarageQual        object\n",
      "GarageCond        object\n",
      "PavedDrive        object\n",
      "WoodDeckSF         int64\n",
      "OpenPorchSF        int64\n",
      "EnclosedPorch      int64\n",
      "3SsnPorch          int64\n",
      "ScreenPorch        int64\n",
      "PoolArea           int64\n",
      "PoolQC            object\n",
      "Fence             object\n",
      "MiscFeature       object\n",
      "MiscVal            int64\n",
      "MoSold             int64\n",
      "YrSold             int64\n",
      "SaleType          object\n",
      "SaleCondition     object\n",
      "SalePrice          int64\n",
      "dtype: object\n",
      "(1447, 65)\n",
      "(1459, 64)\n",
      "New shape train: (1447, 206)\n",
      "Indice da coluna SalePrice no novo dataset 196\n",
      "New shape test: (1459, 205)\n",
      "Colunas que existem apenas teste :  Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def remove_categorical_columns(df):\n",
    "    df.drop('MSZoning',axis=1,inplace=True)\n",
    "    df.drop('Street',axis=1,inplace=True)\n",
    "    df.drop('Alley',axis=1,inplace=True)\n",
    "    df.drop('LotShape',axis=1,inplace=True)\n",
    "    df.drop('LandContour',axis=1,inplace=True)\n",
    "    df.drop('Utilities',axis=1,inplace=True)\n",
    "    df.drop('LotConfig',axis=1,inplace=True)\n",
    "    df.drop('LandSlope',axis=1,inplace=True)\n",
    "    df.drop('Neighborhood',axis=1,inplace=True)\n",
    "    df.drop('Condition1',axis=1,inplace=True)\n",
    "    df.drop('Condition2',axis=1,inplace=True)\n",
    "    df.drop('BldgType',axis=1,inplace=True)\n",
    "    df.drop('HouseStyle',axis=1,inplace=True)\n",
    "    df.drop('RoofStyle',axis=1,inplace=True)\n",
    "    df.drop('RoofMatl',axis=1,inplace=True)\n",
    "    df.drop('Exterior1st',axis=1,inplace=True)\n",
    "    df.drop('Exterior2nd',axis=1,inplace=True)\n",
    "    df.drop('MasVnrType',axis=1,inplace=True)\n",
    "    df.drop('ExterQual',axis=1,inplace=True)\n",
    "    df.drop('ExterCond',axis=1,inplace=True)\n",
    "    df.drop('Foundation',axis=1,inplace=True)\n",
    "    df.drop('BsmtQual',axis=1,inplace=True)\n",
    "    df.drop('BsmtCond',axis=1,inplace=True)\n",
    "    df.drop('BsmtExposure',axis=1,inplace=True)\n",
    "    df.drop('BsmtFinType1',axis=1,inplace=True)\n",
    "    df.drop('BsmtFinType2',axis=1,inplace=True)\n",
    "    df.drop('Heating',axis=1,inplace=True)\n",
    "    df.drop('HeatingQC',axis=1,inplace=True)\n",
    "    df.drop('CentralAir',axis=1,inplace=True)\n",
    "    df.drop('Electrical',axis=1,inplace=True)\n",
    "    df.drop('KitchenQual',axis=1,inplace=True)\n",
    "    df.drop('Functional',axis=1,inplace=True)\n",
    "    df.drop('FireplaceQu',axis=1,inplace=True)\n",
    "    df.drop('GarageType',axis=1,inplace=True)\n",
    "    df.drop('GarageFinish',axis=1,inplace=True)\n",
    "    df.drop('GarageQual',axis=1,inplace=True)\n",
    "    df.drop('GarageCond',axis=1,inplace=True)\n",
    "    df.drop('PavedDrive',axis=1,inplace=True)\n",
    "    df.drop('PoolQC',axis=1,inplace=True)\n",
    "    df.drop('Fence',axis=1,inplace=True)\n",
    "    df.drop('MiscFeature',axis=1,inplace=True)\n",
    "    df.drop('SaleType',axis=1,inplace=True)\n",
    "    df.drop('SaleCondition',axis=1,inplace=True)\n",
    "\n",
    "def input_missing_value(df):\n",
    "    \n",
    "    \n",
    "    #LotFrontage - insert the mean \n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=1)\n",
    "    #print(np.shape(df['LotFrontage']))\n",
    "    df['LotFrontage'] = imp.fit_transform(df['LotFrontage']).transpose()    \n",
    "   \n",
    "    #Alley\n",
    "    df.Alley.fillna(inplace=True,value='No')\n",
    "\n",
    "    #MasVnrType - remove the records where the value is NA\n",
    "    #print(\"Number of lines where MasVnrType has Nan value\", len(df[df['MasVnrType'].isnull()]))\n",
    "    #df.dropna(axis=0,subset=['MasVnrType'],inplace=True)\n",
    "    #print(\"Number of lines where MasVnrType has Nan value\",len(df[df['MasVnrType'].isnull()]))\n",
    "    df.drop('MasVnrType',axis=1,inplace=True)\n",
    "    \n",
    "    #MasVnrArea - remove the hole column\n",
    "    df.drop('MasVnrArea',axis=1,inplace=True)\n",
    "    \n",
    "    #Condition2 - remove the hole column Possui quantidade de tipos diferentes na base de treino e teste e apenas \n",
    "    #um dos tipos é relevante    \n",
    "    df.drop('Condition2',axis=1,inplace=True)\n",
    "    \n",
    "    #RoofMatl - remove the hole column Possui quantidade de tipos diferentes na base de treino e teste e apenas \n",
    "    #um dos tipos é relevante    \n",
    "    df.drop('RoofMatl',axis=1,inplace=True)\n",
    "    \n",
    "\n",
    "    #MSZoning   - tem NA apenas na base de teste. Como nao posso remover linhas removo a coluna   \n",
    "    #df.dropna(axis=0,subset=['MSZoning'],inplace=True)\n",
    "    df.drop('MSZoning',axis=1,inplace=True)\n",
    "    \n",
    "    #BsmtQual\n",
    "    df.BsmtQual.fillna(inplace=True,value='No')\n",
    "    \n",
    "    #HouseStyle - Esse valor so existe na base de treino. Ao inves de remover toda coluna removo somente as linhas \n",
    "    df.drop(df[df.HouseStyle=='2.5Fin'].index,inplace=True)\n",
    "    \n",
    "    #BsmtCond\n",
    "    df.BsmtCond.fillna(inplace=True,value='No')\n",
    "\n",
    "    #BsmtExposure\n",
    "    df.BsmtExposure.fillna(inplace=True,value='No')\n",
    "\n",
    "    #BsmtFinType1\n",
    "    df.BsmtFinType1.fillna(inplace=True,value='No')\n",
    "\n",
    "    #BsmtFinType2\n",
    "    df.BsmtFinType2.fillna(inplace=True,value='No')\n",
    "\n",
    "    #Electrical - remove the records where the value is NA\n",
    "    #print(\"Number of lines where Electrical has Nan value\",len(df[df['Electrical'].isnull()]))\n",
    "    df.dropna(axis=0,subset=['Electrical'],inplace=True) # apenas no treino \n",
    "    df.drop(df[df.Electrical=='Mix'].index,inplace=True) # apenas no treino\n",
    "    #print(\"Number of lines where Electrical has Nan value\",len(df[df['Electrical'].isnull()]))\n",
    "\n",
    "    #FireplaceQu\n",
    "    df.FireplaceQu.fillna(inplace=True,value='No')\n",
    "    \n",
    "\n",
    "    #GarageType\n",
    "    df.GarageType.fillna(inplace=True,value='No')\n",
    "\n",
    "    #GarageYrBlt - remove the hole column\n",
    "    df.drop('GarageYrBlt',axis=1,inplace=True)\n",
    "\n",
    "    #GarageFinish\n",
    "    df.GarageFinish.fillna(inplace=True,value='No')\n",
    "\n",
    "    #GarageQual - A base de teste nao tem um dos tipos presente na base de treino. Assim a base de treino terá uma \n",
    "    #feature para esse tipo e a de teste não. Alem disso, apenas um tipo é pertinente\n",
    "    #Achei melhor entao excluir essa coluna    \n",
    "    df.drop('GarageQual',axis=1,inplace=True)\n",
    "    #df.drop(df[df.GarageQual=='Ex'].index,inplace=True)\n",
    "    \n",
    "    #GarageCond\n",
    "    df.GarageCond.fillna(inplace=True,value='No')\n",
    "\n",
    "    #PoolQC\n",
    "    #df.PoolQC.fillna(inplace=True,value='No')\n",
    "    df.drop('PoolQC',axis=1,inplace=True)\n",
    "    \n",
    "    #Fence\n",
    "    df.Fence.fillna(inplace=True,value='No')\n",
    "\n",
    "    #MiscFeature\n",
    "    #df.MiscFeature.fillna(inplace=True,value='No')\n",
    "    df.drop('MiscFeature',axis=1,inplace=True)\n",
    "\n",
    "    #MiscVal\n",
    "    df.drop('MiscVal',axis=1,inplace=True)\n",
    "    \n",
    "    #SaleType\n",
    "    df.drop('SaleType',axis=1,inplace=True)\n",
    "    \n",
    "    #Exterior1st- nao posso remover linhas do teste\n",
    "    #df.dropna(axis=0,subset=['Exterior1st'],inplace=True)     \n",
    "    #df.drop(df[df.Exterior1st=='Stone'].index,inplace=True)\n",
    "    #df.drop(df[df.Exterior1st=='ImStucc'].index,inplace=True)\n",
    "    #df.drop(df[df.Exterior1st=='CBlock'].index,inplace=True)\n",
    "    df.drop('Exterior1st',axis=1,inplace=True)\n",
    "    \n",
    "    #Exterior2nd\n",
    "    #df.dropna(axis=0,subset=['Exterior2nd'],inplace=True)\n",
    "    #df.Exterior2nd.fillna(inplace=True,value= 'Other')\n",
    "    #df.drop(df[df.Exterior2nd=='Other'].index,inplace=True)\n",
    "    #df.drop(df[df.Exterior2nd=='CBlock'].index,inplace=True)\n",
    "    df.drop('Exterior2nd',axis=1,inplace=True)\n",
    "    \n",
    "    #Heating -- esses tipos existem apenas na base de treino\n",
    "    df.drop(df[df.Heating=='OthW'].index,inplace=True)\n",
    "    df.drop(df[df.Heating=='Floor'].index,inplace=True)\n",
    "    \n",
    "    #KitchenQual\n",
    "    #df.dropna(axis=0,subset=['KitchenQual'],inplace=True)\n",
    "    df.KitchenQual.fillna(inplace=True,value='Fa') #- Apenas a base de teste tem NA e como nao posso remover registro\n",
    "    #dessa base setei o valor menos comum\n",
    "    \n",
    "    #Functional\n",
    "    #df.dropna(axis=0,subset=['Functional'],inplace=True)\n",
    "    df.drop('Functional',axis=1,inplace=True)\n",
    "    \n",
    "    #Utilities\n",
    "    df.drop('Utilities',axis=1,inplace=True)\n",
    "    \n",
    "    #BsmtFinSF1\n",
    "    #df.dropna(axis=0,subset=['BsmtFinSF1'],inplace=True)\n",
    "    df['BsmtFinSF1'] = imp.fit_transform(df['BsmtFinSF1']).transpose()    \n",
    "    \n",
    "    #BsmtFinSF2\n",
    "    #df.dropna(axis=0,subset=['BsmtFinSF2'],inplace=True)\n",
    "    df['BsmtFinSF2'] = imp.fit_transform(df['BsmtFinSF2']).transpose()    \n",
    "    \n",
    "    #BsmtUnfSF\n",
    "    #df.dropna(axis=0,subset=['BsmtUnfSF'],inplace=True)\n",
    "    df.drop('BsmtUnfSF',axis=1,inplace=True)\n",
    "    \n",
    "    #TotalBsmtSF\n",
    "    #df.dropna(axis=0,subset=['TotalBsmtSF'],inplace=True)\n",
    "    df['TotalBsmtSF'] = imp.fit_transform(df['TotalBsmtSF']).transpose()    \n",
    "    \n",
    "    #BsmtFullBath - apenas na base de teste tem NA.Nao posso remover a linha\n",
    "    df.BsmtFullBath.fillna(inplace=True,value='0')\n",
    "    \n",
    "    #BsmtHalfBath- apenas na base de teste tem NA.Nao posso remover a linha\n",
    "    df.BsmtHalfBath.fillna(inplace=True,value='0')\n",
    "    \n",
    "    #GarageCars\n",
    "    #df.dropna(axis=0,subset=['GarageCars'],inplace=True)\n",
    "    df.GarageCars.fillna(value='0',inplace=True)\n",
    "    \n",
    "    #GarageArea\n",
    "    #df.dropna(axis=0,subset=['GarageArea'],inplace=True)\n",
    "    df.GarageArea.fillna(value='0',inplace=True)\n",
    "    \n",
    "df = pd.read_csv(\"train.csv\",na_values=['?','NA'],delimiter=',',delim_whitespace=False)\n",
    "df_test = pd.read_csv(\"test.csv\",na_values=['?','NA'],delimiter=',',delim_whitespace=False)\n",
    "\n",
    "print(df.shape)\n",
    "print(df_test.shape)\n",
    "#print(df.head())\n",
    "#print(df.describe())\n",
    "print(df.dtypes)\n",
    "#df = df.dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "########################Dealing with missing values\n",
    "\n",
    "#missing data\n",
    "# total = df.isnull().sum().sort_values(ascending=False)\n",
    "# percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "# missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "# print(missing_data.head(20))\n",
    "\n",
    "# \n",
    "#               Total   Percent\n",
    "# PoolQC         1453  0.995205\n",
    "# MiscFeature    1406  0.963014\n",
    "# Alley          1369  0.937671\n",
    "# Fence          1179  0.807534\n",
    "# FireplaceQu     690  0.472603\n",
    "# LotFrontage     259  0.177397\n",
    "# GarageCond       81  0.055479\n",
    "# GarageType       81  0.055479\n",
    "# GarageYrBlt      81  0.055479\n",
    "# GarageFinish     81  0.055479\n",
    "# GarageQual       81  0.055479\n",
    "# BsmtExposure     38  0.026027\n",
    "# BsmtFinType2     38  0.026027\n",
    "# BsmtFinType1     37  0.025342\n",
    "# BsmtCond         37  0.025342\n",
    "# BsmtQual         37  0.025342\n",
    "# MasVnrArea        8  0.005479\n",
    "# MasVnrType        8  0.005479\n",
    "# Electrical        1  0.000685\n",
    "# Utilities         0  0.000000\n",
    "\n",
    "\n",
    "\n",
    "#print(df.columns[df.isnull().any()])\n",
    "#'LotFrontage', 'Alley', 'MasVnrType', 'MasVnrArea', 'BsmtQual',\n",
    "#       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "#       'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
    "#       'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence',\n",
    "#       'MiscFeature'\n",
    "input_missing_value(df)\n",
    "\n",
    "\n",
    "#print(df_test.columns[df_test.isnull().any()])\n",
    "#Index(['MSZoning', 'LotFrontage', 'Alley', 'Utilities', 'Exterior1st',\n",
    "#       'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond',\n",
    "#       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
    "#      'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n",
    "#       'BsmtHalfBath', 'KitchenQual', 'Functional', 'FireplaceQu',\n",
    "#      'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea',\n",
    "#       'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature',\n",
    "#       'SaleType'],\n",
    "\n",
    "input_missing_value(df_test)\n",
    "\n",
    "#Valores numericos que continham NA sao detectados como String. Assim, depois que removemos o NA temos que setar corretamente \n",
    "#o tipo \n",
    "df_test.BsmtFullBath = df_test.BsmtFullBath.astype(\"int64\")\n",
    "df_test.BsmtHalfBath = df_test.BsmtHalfBath.astype(\"int64\")\n",
    "df_test.GarageCars = df_test.GarageCars.astype(\"int64\")\n",
    "df_test.GarageArea = df_test.GarageArea.astype(\"int64\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "########################End dealing with missing values\n",
    "\n",
    "\n",
    "# The OneHotEncoder converts features represented as numeric codes (so they are values that can't be ordered) to their binary representation\n",
    "#enc = preprocessing.OneHotEncoder() \n",
    "#aux = enc.fit_transform(data_train)\n",
    "\n",
    "\n",
    "########################Tratando campos nominais\n",
    "\n",
    "vec = DictVectorizer()\n",
    "aux = np.asmatrix(vec.fit_transform(df.transpose().to_dict().values()).toarray())\n",
    "\n",
    "data_train = pd.DataFrame(aux,columns=vec.feature_names_)\n",
    "#data_train = pd.get_dummies(df)\n",
    "\n",
    "\n",
    "data_train.to_csv('train_no_categorical.csv')\n",
    "\n",
    "print(\"New shape train:\" , np.shape(data_train))\n",
    "print(\"Indice da coluna SalePrice no novo dataset\" , data_train.columns.get_loc('SalePrice'))\n",
    "\n",
    "################################################# Base de teste\n",
    "\n",
    "vec = DictVectorizer()\n",
    "aux_test = vec.fit_transform(df_test.transpose().to_dict().values()).toarray()\n",
    "data_test = pd.DataFrame(aux_test,columns=vec.feature_names_)\n",
    "#data_test = pd.get_dummies(df_test)\n",
    " \n",
    "print(\"New shape test:\" , np.shape(data_test))\n",
    "\n",
    "data_test.to_csv('test_no_categorical.csv')\n",
    "\n",
    "\n",
    "print(\"Colunas que existem apenas teste : \" , data_test.columns.difference(data_train.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      1447.000000\n",
      "mean     180944.330339\n",
      "std       79185.190380\n",
      "min       34900.000000\n",
      "25%      130000.000000\n",
      "50%      163000.000000\n",
      "75%      214000.000000\n",
      "max      755000.000000\n",
      "Name: SalePrice, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAPUCAYAAABMx1tcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+AGgiPADQJH/B/dcNoZnJ+VXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff1e07d68d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh0AAAFoCAYAAADzZ0kIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZJUCUOHJEmqhKFDkiRVwtAhSZIq8f8BCcK0DHeF54sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff1e06afb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhMAAAFoCAYAAADtrnm7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKmKYkCRJRf4/rvPRIEY61L4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff1e0bcf240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "print(df.SalePrice.describe())\n",
    "\n",
    "saleprice_scaled = preprocessing.StandardScaler().fit_transform((df['SalePrice'][:,np.newaxis]));\n",
    "fig = plt.figure(1, figsize=(6, 12))\n",
    "#ax = fig.add_subplot(111)\n",
    "#ax.boxplot(saleprice_scaled)\n",
    "plt.boxplot(saleprice_scaled)\n",
    "\n",
    "plt.figure()\n",
    "x = plt.hist(df['SalePrice'],bins=50)\n",
    "\n",
    "plt.figure()\n",
    "saleprice_log = np.log(df['SalePrice'])\n",
    "x = plt.hist(saleprice_log,bins=50)\n",
    "\n",
    "#df['SalePrice'] = np.log(df['SalePrice'])\n",
    "#df_test['SalePrice'] = np.log(df_test['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tentativa de selecionar melhores features \n",
      "\n",
      "As features selecionadas com Tree-based feature selection foram: \n",
      "\n",
      "['ExterQual=TA' 'BsmtQual=Ex' 'OverallQual' 'GrLivArea' 'GarageCars'\n",
      " 'FireplaceQu=No' 'FullBath' 'Neighborhood=NoRidge' '1stFlrSF' '2ndFlrSF'\n",
      " 'GarageArea' 'Fireplaces' 'BsmtFinSF1' 'LotArea' 'TotalBsmtSF'\n",
      " 'TotRmsAbvGrd' 'BsmtFinType1=GLQ' 'YearRemodAdd' 'YearBuilt' 'BsmtQual=Gd'\n",
      " 'LotFrontage' 'BldgType=1Fam' 'BsmtExposure=Gd' 'ExterQual=Fa' 'HalfBath']\n",
      "[[ 0.29182382  0.1115427   0.10393447  0.07373928  0.06535079  0.03346214\n",
      "   0.02486973  0.02065555  0.01931133  0.01850605  0.01129692  0.01015791\n",
      "   0.00951359  0.00930044  0.0090668   0.00851093  0.00733696  0.00689751\n",
      "   0.00664215  0.00634419  0.0059271   0.00541231  0.00507997  0.00474002\n",
      "   0.00424938]]\n",
      "\n",
      " New shape train apos Tree-based feature selection: (1447, 23)\n",
      "\n",
      " Fim tentativa selecionar melhores features \n",
      "\n",
      "\n",
      " New shape test apos Tree-based feature selection: (1459, 23)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Tentativa de selecionar melhores features \\n\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "#Removing features with low variance\n",
    "#print(\"Original shape: {}\".format(np.shape(df.iloc[:,0:-1])))\n",
    "#sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "#features = sel.fit_transform(df.iloc[:,0:-1])\n",
    "#print(\"Shape apos Removing features with low variance {}\".format(np.shape(features))) #nenhuma foi selecionada \n",
    "#print(\"\\n\")\n",
    "\n",
    "#Tree-based feature selection\n",
    "y_train = (data_train['SalePrice'])\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "\n",
    "clf = ExtraTreesRegressor()\n",
    "clf = clf.fit(x_train,y_train)\n",
    "data = np.zeros((1,x_train.shape[1])) \n",
    "data = pd.DataFrame(data, columns=x_train.columns)\n",
    "data.iloc[0] = clf.feature_importances_\n",
    "data = data.T.sort_values(df.index[0], ascending=False).T\n",
    "\n",
    "\n",
    "print(\"As features selecionadas com Tree-based feature selection foram: \\n\")\n",
    "yyy = np.asarray((data.columns[0:25]))\n",
    "xxx = np.asarray((data.iloc[:,0:25]))\n",
    "print(yyy)\n",
    "print(xxx)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "aux = model.transform(x_train)\n",
    "\n",
    "print(\"\\n New shape train apos Tree-based feature selection: {}\".format(aux.shape))\n",
    "\n",
    "print(\"\\n Fim tentativa selecionar melhores features \\n\")\n",
    "\n",
    "\n",
    "data_train_less_features = pd.concat([pd.DataFrame(aux),pd.DataFrame(y_train)],axis=1)\n",
    "data_train_less_features.to_csv('data_train_less_features.csv')\n",
    "\n",
    "\n",
    "aux = model.transform((data_test))\n",
    "data_test_less_features = pd.DataFrame(aux)\n",
    "print(\"\\n New shape test apos Tree-based feature selection: {}\".format(aux.shape))\n",
    "data_test_less_features.to_csv('data_test_less_features.csv')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn   import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso 1 - Linear Regression \n",
      "Fold #1\n",
      "Fold score (RMSE): 47942668564128248.00\n",
      "Accuracy: -322049931582137899679744.000\n",
      "Fold #2\n",
      "Fold score (RMSE): 160065663803069408.00\n",
      "Accuracy: -5075676790950259928858624.000\n",
      "Fold #3\n",
      "Fold score (RMSE): 490855841291164544.00\n",
      "Accuracy: -52762282399043161975422976.000\n",
      "Fold #4\n",
      "Fold score (RMSE): 57051.01\n",
      "Accuracy: 0.475\n",
      "Fold #5\n",
      "Fold score (RMSE): 31741.90\n",
      "Accuracy: 0.878\n",
      "\n",
      " Average RMSE: 2.3176878051774726e+17\n",
      "\n",
      "\n",
      "\n",
      "SGDRegressor \n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 41086.46\n",
      "Accuracy: 0.763\n",
      "Fold #2\n",
      "Fold score (RMSE): 35005.00\n",
      "Accuracy: 0.757\n",
      "Fold #3\n",
      "Fold score (RMSE): 32791.33\n",
      "Accuracy: 0.765\n",
      "Fold #4\n",
      "Fold score (RMSE): 104251.38\n",
      "Accuracy: -0.753\n",
      "Fold #5\n",
      "Fold score (RMSE): 41161.59\n",
      "Accuracy: 0.796\n",
      "\n",
      " Average RMSE: 57512.668645347585\n",
      "\n",
      "\n",
      " Less Features\n",
      "Fold #1\n",
      "Fold score (RMSE): 26130.72\n",
      "Accuracy: 0.870\n",
      "Fold #2\n",
      "Fold score (RMSE): 34542.78\n",
      "Accuracy: 0.817\n",
      "Fold #3\n",
      "Fold score (RMSE): 35442.62\n",
      "Accuracy: 0.835\n",
      "Fold #4\n",
      "Fold score (RMSE): 26301.29\n",
      "Accuracy: 0.866\n",
      "Fold #5\n",
      "Fold score (RMSE): 45231.30\n",
      "Accuracy: 0.696\n",
      "\n",
      " Average RMSE: 34258.41688253322\n",
      "\n",
      "\n",
      "\n",
      "SGDRegressor \n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 29098.61\n",
      "Accuracy: 0.839\n",
      "Fold #2\n",
      "Fold score (RMSE): 35459.14\n",
      "Accuracy: 0.807\n",
      "Fold #3\n",
      "Fold score (RMSE): 36299.06\n",
      "Accuracy: 0.827\n",
      "Fold #4\n",
      "Fold score (RMSE): 31369.28\n",
      "Accuracy: 0.809\n",
      "Fold #5\n",
      "Fold score (RMSE): 42926.44\n",
      "Accuracy: 0.726\n",
      "\n",
      " Average RMSE: 35346.98250053026\n"
     ]
    }
   ],
   "source": [
    "#Starting making predictors\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "\n",
    "#Caso 1 - Linear Regression \n",
    "print(\"Caso 1 - Linear Regression \")\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#Normalization\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = LinearRegression()\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# The mean squared error\n",
    "#pred = classifier.predict(x_test_scaled)\n",
    "#score = metrics.mean_squared_error(y_test, pred)\n",
    "#print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "\n",
    "# Evaluate success using accuracy\n",
    "#print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"SGDRegressor \\n\\n\")\n",
    "\n",
    "classifier = SGDRegressor()\n",
    "\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "###########Less features\n",
    "\n",
    "print(\"\\n\\n Less Features\")\n",
    "#Normalization\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = LinearRegression()\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"SGDRegressor \\n\\n\")\n",
    "\n",
    "classifier = SGDRegressor()\n",
    "\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Fold #1\n",
      "Fold score (RMSE): 24099.64\n",
      "Accuracy: 0.896\n",
      "Fold #2\n",
      "Fold score (RMSE): 25149.93\n",
      "Accuracy: 0.899\n",
      "Fold #3\n",
      "Fold score (RMSE): 28238.42\n",
      "Accuracy: 0.899\n",
      "Fold #4\n",
      "Fold score (RMSE): 32066.71\n",
      "Accuracy: 0.827\n",
      "Fold #5\n",
      "Fold score (RMSE): 41419.54\n",
      "Accuracy: 0.693\n",
      "\n",
      " Average RMSE: 30829.185125594016\n",
      "\n",
      "\n",
      " Less features \n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 24860.41\n",
      "Accuracy: 0.883\n",
      "Fold #2\n",
      "Fold score (RMSE): 33350.51\n",
      "Accuracy: 0.830\n",
      "Fold #3\n",
      "Fold score (RMSE): 34970.35\n",
      "Accuracy: 0.839\n",
      "Fold #4\n",
      "Fold score (RMSE): 25646.57\n",
      "Accuracy: 0.872\n",
      "Fold #5\n",
      "Fold score (RMSE): 45211.13\n",
      "Accuracy: 0.696\n",
      "\n",
      " Average RMSE: 33624.92345968869\n"
     ]
    }
   ],
   "source": [
    "#Caso 3 - SVM\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import NuSVR\n",
    "\n",
    "print(\"SVM\")\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#Normalization\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train = scaler.transform((x_train))\n",
    "x_train = np.ascontiguousarray(x_train)\n",
    "\n",
    "\n",
    "classifier = NuSVR(kernel='linear', C=1e3) #34761.27693615821\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# Write the cross-validated prediction\n",
    "\n",
    "pred = []\n",
    "pred = np.array(pred,dtype='float64')\n",
    "pred = classifier.predict(np.asmatrix(data_test))\n",
    "\n",
    "result = pd.DataFrame(pred,columns=['SalePrice'], index=range(1461,2920))\n",
    "\n",
    "\n",
    "result.to_csv('pred_SVR.csv', columns=['SalePrice'])\n",
    "\n",
    "\n",
    "# The mean squared error\n",
    "#pred = classifier.predict(x_test_scaled)\n",
    "#score = metrics.mean_squared_error(y_test, pred)\n",
    "#print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "\n",
    "# Evaluate success using accuracy\n",
    "#print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "###########Less features\n",
    "print(\"\\n\\n Less features \\n\")\n",
    "#Normalization\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train = scaler.transform((x_train))\n",
    "x_train = np.ascontiguousarray(x_train)\n",
    "\n",
    "\n",
    "#classifier = SVR(kernel='rbf', C=1e3, gamma=0.1) #66483.84692815947\n",
    "classifier = NuSVR(kernel='linear', C=1e3) #34761.27693615821\n",
    "#classifier = SVR(kernel='poly', C=1e3, degree=3) #86747.4465877091\n",
    "#classifier = NuSVR(C=1e3) #57249.1589623674\n",
    "\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN MLPRegressor\n",
      "Fold #1\n",
      "Fold score (RMSE): 45320.96\n",
      "Accuracy: 0.621\n",
      "Fold #2\n",
      "Fold score (RMSE): 35137.56\n",
      "Accuracy: 0.782\n",
      "Fold #3\n",
      "Fold score (RMSE): 49356.83\n",
      "Accuracy: 0.624\n",
      "Fold #4\n",
      "Fold score (RMSE): 36481.53\n",
      "Accuracy: 0.764\n",
      "Fold #5\n",
      "Fold score (RMSE): 39438.61\n",
      "Accuracy: 0.806\n",
      "\n",
      " Average RMSE: 41498.19821620857\n",
      "\n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 27769.05\n",
      "Accuracy: 0.853\n",
      "Fold #2\n",
      "Fold score (RMSE): 37426.03\n",
      "Accuracy: 0.785\n",
      "Fold #3\n",
      "Fold score (RMSE): 36830.69\n",
      "Accuracy: 0.821\n",
      "Fold #4\n",
      "Fold score (RMSE): 28042.38\n",
      "Accuracy: 0.847\n",
      "Fold #5\n",
      "Fold score (RMSE): 46200.21\n",
      "Accuracy: 0.683\n",
      "\n",
      " Average RMSE: 35910.3153732177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Shuffle\n",
    "print(\"NN MLPRegressor\")\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#Normalization\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10,4,2), random_state=1)\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# The mean squared error\n",
    "#pred = classifier.predict(x_test_scaled)\n",
    "#score = metrics.mean_squared_error(y_test, pred)\n",
    "#print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "\n",
    "# Evaluate success using accuracy\n",
    "#print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "###########Less features\n",
    "print(\"\\n\\n\")\n",
    "#Normalization\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(8,2), random_state=1)\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests\n",
      "Mean squared error: 32932.397455948325\n",
      "Accuracy: 0.781\n",
      "\n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 37129.938257305854\n",
      "Accuracy: 0.800\n",
      "Fold #2\n",
      "Fold score (RMSE): 26156.79711174648\n",
      "Accuracy: 0.876\n",
      "Fold #3\n",
      "Fold score (RMSE): 31897.063543493263\n",
      "Accuracy: 0.850\n",
      "Fold #4\n",
      "Fold score (RMSE): 29749.582824598518\n",
      "Accuracy: 0.812\n",
      "Fold #5\n",
      "Fold score (RMSE): 27342.285480648727\n",
      "Accuracy: 0.897\n",
      "\n",
      " Average RMSE: 30703.3716831098\n",
      "\n",
      "\n",
      "\n",
      "Mean squared error: 24939.623794998082\n",
      "Accuracy: 0.913\n",
      "\n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 27724.680507793797\n",
      "Accuracy: 0.854\n",
      "Fold #2\n",
      "Fold score (RMSE): 33228.719974833984\n",
      "Accuracy: 0.831\n",
      "Fold #3\n",
      "Fold score (RMSE): 31328.845779078314\n",
      "Accuracy: 0.871\n",
      "Fold #4\n",
      "Fold score (RMSE): 26189.863617624902\n",
      "Accuracy: 0.867\n",
      "Fold #5\n",
      "Fold score (RMSE): 29872.411139518736\n",
      "Accuracy: 0.867\n",
      "\n",
      " Average RMSE: 29775.550350252495\n"
     ]
    }
   ],
   "source": [
    "##Random Forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Shuffle\n",
    "print(\"Random Forests\")\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_train.drop('SalePrice',axis=1), data_train['SalePrice'], test_size=0.20, random_state=42)\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test,y=y_test))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train.as_matrix()[training]\n",
    "    y_train_fold = y_train.as_matrix()[training]\n",
    "    x_test_fold = x_train.as_matrix()[test]\n",
    "    y_test_fold = y_train.as_matrix()[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "\n",
    "###########Less features\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_train_less_features.drop('SalePrice',axis=1), \n",
    "                                    data_train_less_features['SalePrice'], test_size=0.20, random_state=42)\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test,y=y_test))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train.as_matrix()[training]\n",
    "    y_train_fold = y_train.as_matrix()[training]\n",
    "    x_test_fold = x_train.as_matrix()[test]\n",
    "    y_test_fold = y_train.as_matrix()[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# Write the cross-validated prediction\n",
    "\n",
    "pred = []\n",
    "pred = np.array(pred,dtype='float64')\n",
    "pred = classifier.predict(np.asmatrix(data_test_less_features))\n",
    "\n",
    "result = pd.DataFrame(pred,columns=['SalePrice'], index=range(1461,2920))\n",
    "\n",
    "\n",
    "result.to_csv('pred_RF.csv', columns=['SalePrice'])\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
