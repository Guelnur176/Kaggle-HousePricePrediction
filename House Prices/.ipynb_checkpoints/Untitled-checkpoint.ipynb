{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n",
      "(1445, 66)\n",
      "(1459, 65)\n",
      "Id                 int64\n",
      "MSSubClass        object\n",
      "LotFrontage      float64\n",
      "LotArea            int64\n",
      "Street            object\n",
      "Alley             object\n",
      "LotShape          object\n",
      "LandContour       object\n",
      "LotConfig         object\n",
      "LandSlope         object\n",
      "Neighborhood      object\n",
      "Condition1        object\n",
      "BldgType          object\n",
      "HouseStyle        object\n",
      "OverallQual        int64\n",
      "OverallCond       object\n",
      "YearBuilt          int64\n",
      "YearRemodAdd       int64\n",
      "RoofStyle         object\n",
      "MasVnrType        object\n",
      "ExterQual         object\n",
      "ExterCond         object\n",
      "Foundation        object\n",
      "BsmtQual          object\n",
      "BsmtCond          object\n",
      "BsmtExposure      object\n",
      "BsmtFinType1      object\n",
      "BsmtFinSF1       float64\n",
      "BsmtFinType2      object\n",
      "BsmtFinSF2       float64\n",
      "                  ...   \n",
      "2ndFlrSF           int64\n",
      "LowQualFinSF       int64\n",
      "GrLivArea          int64\n",
      "BsmtFullBath       int64\n",
      "BsmtHalfBath       int64\n",
      "FullBath           int64\n",
      "HalfBath           int64\n",
      "BedroomAbvGr       int64\n",
      "KitchenAbvGr      object\n",
      "KitchenQual       object\n",
      "TotRmsAbvGrd       int64\n",
      "Fireplaces         int64\n",
      "FireplaceQu       object\n",
      "GarageType        object\n",
      "GarageFinish      object\n",
      "GarageCars         int64\n",
      "GarageArea         int64\n",
      "GarageCond        object\n",
      "PavedDrive        object\n",
      "WoodDeckSF         int64\n",
      "OpenPorchSF        int64\n",
      "EnclosedPorch      int64\n",
      "3SsnPorch          int64\n",
      "ScreenPorch        int64\n",
      "PoolArea           int64\n",
      "Fence             object\n",
      "MoSold            object\n",
      "YrSold            object\n",
      "SaleCondition     object\n",
      "SalePrice          int64\n",
      "Length: 66, dtype: object\n",
      "Null values treino \n",
      " Index([], dtype='object')\n",
      "Null values test \n",
      " Index([], dtype='object')\n",
      "New shape train: (1445, 249)\n",
      "Indice da coluna SalePrice no novo dataset 235\n",
      "New shape test: (1459, 248)\n",
      "Colunas que existem apenas teste :  Index([], dtype='object')\n",
      "Colunas que existem apenas treino :  Index(['SalePrice'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def remove_categorical_columns(df):\n",
    "    df.drop('MSZoning',axis=1,inplace=True)\n",
    "    df.drop('Street',axis=1,inplace=True)\n",
    "    df.drop('Alley',axis=1,inplace=True)\n",
    "    df.drop('LotShape',axis=1,inplace=True)\n",
    "    df.drop('LandContour',axis=1,inplace=True)\n",
    "    df.drop('Utilities',axis=1,inplace=True)\n",
    "    df.drop('LotConfig',axis=1,inplace=True)\n",
    "    df.drop('LandSlope',axis=1,inplace=True)\n",
    "    df.drop('Neighborhood',axis=1,inplace=True)\n",
    "    df.drop('Condition1',axis=1,inplace=True)\n",
    "    df.drop('Condition2',axis=1,inplace=True)\n",
    "    df.drop('BldgType',axis=1,inplace=True)\n",
    "    df.drop('HouseStyle',axis=1,inplace=True)\n",
    "    df.drop('RoofStyle',axis=1,inplace=True)\n",
    "    df.drop('RoofMatl',axis=1,inplace=True)\n",
    "    df.drop('Exterior1st',axis=1,inplace=True)\n",
    "    df.drop('Exterior2nd',axis=1,inplace=True)\n",
    "    df.drop('MasVnrType',axis=1,inplace=True)\n",
    "    df.drop('ExterQual',axis=1,inplace=True)\n",
    "    df.drop('ExterCond',axis=1,inplace=True)\n",
    "    df.drop('Foundation',axis=1,inplace=True)\n",
    "    df.drop('BsmtQual',axis=1,inplace=True)\n",
    "    df.drop('BsmtCond',axis=1,inplace=True)\n",
    "    df.drop('BsmtExposure',axis=1,inplace=True)\n",
    "    df.drop('BsmtFinType1',axis=1,inplace=True)\n",
    "    df.drop('BsmtFinType2',axis=1,inplace=True)\n",
    "    df.drop('Heating',axis=1,inplace=True)\n",
    "    df.drop('HeatingQC',axis=1,inplace=True)\n",
    "    df.drop('CentralAir',axis=1,inplace=True)\n",
    "    df.drop('Electrical',axis=1,inplace=True)\n",
    "    df.drop('KitchenQual',axis=1,inplace=True)\n",
    "    df.drop('Functional',axis=1,inplace=True)\n",
    "    df.drop('FireplaceQu',axis=1,inplace=True)\n",
    "    df.drop('GarageType',axis=1,inplace=True)\n",
    "    df.drop('GarageFinish',axis=1,inplace=True)\n",
    "    df.drop('GarageQual',axis=1,inplace=True)\n",
    "    df.drop('GarageCond',axis=1,inplace=True)\n",
    "    df.drop('PavedDrive',axis=1,inplace=True)\n",
    "    df.drop('PoolQC',axis=1,inplace=True)\n",
    "    df.drop('Fence',axis=1,inplace=True)\n",
    "    df.drop('MiscFeature',axis=1,inplace=True)\n",
    "    df.drop('SaleType',axis=1,inplace=True)\n",
    "    df.drop('SaleCondition',axis=1,inplace=True)\n",
    "\n",
    "def input_missing_value(df):\n",
    "    \n",
    "    # MSSubClass as str\n",
    "    df['MSSubClass'] = df['MSSubClass'].astype(\"str\")\n",
    "    #After converting this column to String, it will be handled as categorical\n",
    "    #There is one value in the test set that there isn't in the training. It is 150\n",
    "    #It will be result in one column for this categorical value that doesn't exist in the training set\n",
    "    #It can't happen\n",
    "    #There is only one value 150 in the row 1358 in the test set\n",
    "    #We also can't remove any single row from the test set as we will need make predictions for all rows \n",
    "    #Let's just pass the value 150 to 40 , as this value exists in booth sets and is is the less common \n",
    "    df['MSSubClass'][df.MSSubClass=='150']='40'\n",
    "    \n",
    "    # Converting OverallCond to str\n",
    "    df.OverallCond = df.OverallCond.astype(\"str\")\n",
    "    \n",
    "    # KitchenAbvGr to categorical\n",
    "    df['KitchenAbvGr'] = df['KitchenAbvGr'].astype(\"str\")\n",
    "    df.drop(df[df.KitchenAbvGr=='3'].index,inplace=True) # apenas no treino\n",
    "    \n",
    "    # Year and Month to categorical\n",
    "    df['YrSold'] = df['YrSold'].astype(\"str\")\n",
    "    df['MoSold'] = df['MoSold'].astype(\"str\")    \n",
    "    \n",
    "    #LotFrontage - insert the mean \n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=1)\n",
    "    #print(np.shape(df['LotFrontage']))\n",
    "    df['LotFrontage'] = imp.fit_transform(df['LotFrontage'].reshape(1,-1)).transpose()    \n",
    "   \n",
    "    #Alley\n",
    "    df.Alley.fillna(inplace=True,value='No')\n",
    "\n",
    "    #MasVnrType - remove the records where the value is NA \n",
    "    #print(\"Number of lines where MasVnrType has Nan value\", len(df[df['MasVnrType'].isnull()]))\n",
    "    #df.dropna(axis=0,subset=['MasVnrType'],inplace=True)\n",
    "    #df.drop('MasVnrType',axis=1,inplace=True)\n",
    "    # MasVnrType NA in all. filling with most popular values\n",
    "    df.MasVnrType.fillna(value=df['MasVnrType'].mode()[0],inplace=True)\n",
    "    \n",
    "    #MasVnrArea - remove the hole column\n",
    "    df.drop('MasVnrArea',axis=1,inplace=True)\n",
    "    \n",
    "    #Condition2 - remove the hole column Possui quantidade de tipos diferentes na base de treino e teste e apenas \n",
    "    #um dos tipos é relevante    \n",
    "    df.drop('Condition2',axis=1,inplace=True)\n",
    "    \n",
    "    #RoofMatl - remove the hole column Possui quantidade de tipos diferentes na base de treino e teste e apenas \n",
    "    #um dos tipos é relevante    \n",
    "    df.drop('RoofMatl',axis=1,inplace=True)\n",
    "    \n",
    "\n",
    "    #MSZoning   - tem NA apenas na base de teste. Como nao posso remover linhas removo a coluna   \n",
    "    #df.dropna(axis=0,subset=['MSZoning'],inplace=True)\n",
    "    df.drop('MSZoning',axis=1,inplace=True)\n",
    "    #df.MSZoning.fillna(df['MSZoning'].mode()[0])\n",
    "\n",
    "    \n",
    "    #BsmtQual\n",
    "    df.BsmtQual.fillna(inplace=True,value='No')\n",
    "    \n",
    "    #HouseStyle - Esse valor so existe na base de treino. Ao inves de remover toda coluna removo somente as linhas \n",
    "    df.drop(df[df.HouseStyle=='2.5Fin'].index,inplace=True)\n",
    "    \n",
    "    #BsmtCond\n",
    "    df.BsmtCond.fillna(inplace=True,value='No')\n",
    "\n",
    "    #BsmtExposure\n",
    "    df.BsmtExposure.fillna(inplace=True,value='No')\n",
    "\n",
    "    #BsmtFinType1\n",
    "    df.BsmtFinType1.fillna(inplace=True,value='No')\n",
    "\n",
    "    #BsmtFinType2\n",
    "    df.BsmtFinType2.fillna(inplace=True,value='No')\n",
    "\n",
    "    #Electrical - remove the records where the value is NA\n",
    "    #print(\"Number of lines where Electrical has Nan value\",len(df[df['Electrical'].isnull()]))\n",
    "    df.dropna(axis=0,subset=['Electrical'],inplace=True) # apenas no treino \n",
    "    df.drop(df[df.Electrical=='Mix'].index,inplace=True) # apenas no treino\n",
    "    #print(\"Number of lines where Electrical has Nan value\",len(df[df['Electrical'].isnull()]))\n",
    "\n",
    "    #FireplaceQu\n",
    "    df.FireplaceQu.fillna(inplace=True,value='No')\n",
    "    \n",
    "\n",
    "    #GarageType\n",
    "    df.GarageType.fillna(inplace=True,value='No')\n",
    "\n",
    "    #GarageYrBlt - remove the hole column\n",
    "    df.drop('GarageYrBlt',axis=1,inplace=True)\n",
    "\n",
    "    #GarageFinish\n",
    "    df.GarageFinish.fillna(inplace=True,value='No')\n",
    "\n",
    "    #GarageQual - A base de teste nao tem um dos tipos presente na base de treino. Assim a base de treino terá uma \n",
    "    #feature para esse tipo e a de teste não. Alem disso, apenas um tipo é pertinente\n",
    "    #Achei melhor entao excluir essa coluna    \n",
    "    df.drop('GarageQual',axis=1,inplace=True)\n",
    "    #df.drop(df[df.GarageQual=='Ex'].index,inplace=True)\n",
    "    \n",
    "    #GarageCond\n",
    "    df.GarageCond.fillna(inplace=True,value='No')\n",
    "\n",
    "    #PoolQC\n",
    "    #df.PoolQC.fillna(inplace=True,value='No')\n",
    "    df.drop('PoolQC',axis=1,inplace=True)\n",
    "    \n",
    "    #Fence\n",
    "    df.Fence.fillna(inplace=True,value='No')\n",
    "\n",
    "    #MiscFeature\n",
    "    #df.MiscFeature.fillna(inplace=True,value='No')\n",
    "    df.drop('MiscFeature',axis=1,inplace=True)\n",
    "\n",
    "    #MiscVal\n",
    "    df.drop('MiscVal',axis=1,inplace=True)\n",
    "    \n",
    "    #SaleType\n",
    "    df.drop('SaleType',axis=1,inplace=True)\n",
    "    \n",
    "    #Exterior1st- nao posso remover linhas do teste\n",
    "    #df.dropna(axis=0,subset=['Exterior1st'],inplace=True)     \n",
    "    #df.drop(df[df.Exterior1st=='Stone'].index,inplace=True)\n",
    "    #df.drop(df[df.Exterior1st=='ImStucc'].index,inplace=True)\n",
    "    #df.drop(df[df.Exterior1st=='CBlock'].index,inplace=True)\n",
    "    df.drop('Exterior1st',axis=1,inplace=True)\n",
    "    \n",
    "    #Exterior2nd\n",
    "    #df.dropna(axis=0,subset=['Exterior2nd'],inplace=True)\n",
    "    #df.Exterior2nd.fillna(inplace=True,value= 'Other')\n",
    "    #df.drop(df[df.Exterior2nd=='Other'].index,inplace=True)\n",
    "    #df.drop(df[df.Exterior2nd=='CBlock'].index,inplace=True)\n",
    "    df.drop('Exterior2nd',axis=1,inplace=True)\n",
    "    \n",
    "    #Heating -- esses tipos existem apenas na base de treino\n",
    "    df.drop(df[df.Heating=='OthW'].index,inplace=True)\n",
    "    df.drop(df[df.Heating=='Floor'].index,inplace=True)\n",
    "    \n",
    "    #KitchenQual\n",
    "    #df.dropna(axis=0,subset=['KitchenQual'],inplace=True)\n",
    "    df.KitchenQual.fillna(inplace=True,value='Fa') #- Apenas a base de teste tem NA e como nao posso remover registro\n",
    "    #dessa base setei o valor menos comum\n",
    "    \n",
    "    #Functional\n",
    "    #df.dropna(axis=0,subset=['Functional'],inplace=True)\n",
    "    df.drop('Functional',axis=1,inplace=True)\n",
    "    \n",
    "    #Utilities\n",
    "    df.drop('Utilities',axis=1,inplace=True)\n",
    "    \n",
    "    #BsmtFinSF1\n",
    "    #df.dropna(axis=0,subset=['BsmtFinSF1'],inplace=True)\n",
    "    df['BsmtFinSF1'] = imp.fit_transform(df['BsmtFinSF1'].reshape(1,-1)).transpose()    \n",
    "    \n",
    "    #BsmtFinSF2\n",
    "    #df.dropna(axis=0,subset=['BsmtFinSF2'],inplace=True)\n",
    "    df['BsmtFinSF2'] = imp.fit_transform(df['BsmtFinSF2'].reshape(1,-1)).transpose()    \n",
    "    \n",
    "    #BsmtUnfSF\n",
    "    #df.dropna(axis=0,subset=['BsmtUnfSF'],inplace=True)\n",
    "    df.drop('BsmtUnfSF',axis=1,inplace=True)\n",
    "    \n",
    "    #TotalBsmtSF\n",
    "    #df.dropna(axis=0,subset=['TotalBsmtSF'],inplace=True)\n",
    "    #df['TotalBsmtSF'] = imp.fit_transform(df['TotalBsmtSF']).transpose()    \n",
    "    df.TotalBsmtSF.fillna(value=0,inplace=True)\n",
    "    \n",
    "    #BsmtFullBath - apenas na base de teste tem NA.Nao posso remover a linha\n",
    "    df.BsmtFullBath.fillna(inplace=True,value=0)\n",
    "    \n",
    "    #BsmtHalfBath- apenas na base de teste tem NA.Nao posso remover a linha\n",
    "    df.BsmtHalfBath.fillna(inplace=True,value=0)\n",
    "    \n",
    "    #GarageCars\n",
    "    #df.dropna(axis=0,subset=['GarageCars'],inplace=True)\n",
    "    df.GarageCars.fillna(value=0,inplace=True)\n",
    "    \n",
    "    #GarageArea\n",
    "    #df.dropna(axis=0,subset=['GarageArea'],inplace=True)\n",
    "    df.GarageArea.fillna(value=0,inplace=True)\n",
    "    \n",
    "df = pd.read_csv(\"train.csv\",na_values=['?','NA'],delimiter=',',delim_whitespace=False)\n",
    "df_test = pd.read_csv(\"test.csv\",na_values=['?','NA'],delimiter=',',delim_whitespace=False)\n",
    "\n",
    "print(df.shape)\n",
    "print(df_test.shape)\n",
    "#print(df.head())\n",
    "#print(df.describe())\n",
    "#print(df.dtypes)\n",
    "#df = df.dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "\n",
    "########################Dealing with missing values\n",
    "\n",
    "#missing data\n",
    "# total = df.isnull().sum().sort_values(ascending=False)\n",
    "# percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "# missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "# print(missing_data.head(20))\n",
    "\n",
    "# \n",
    "#               Total   Percent\n",
    "# PoolQC         1453  0.995205\n",
    "# MiscFeature    1406  0.963014\n",
    "# Alley          1369  0.937671\n",
    "# Fence          1179  0.807534\n",
    "# FireplaceQu     690  0.472603\n",
    "# LotFrontage     259  0.177397\n",
    "# GarageCond       81  0.055479\n",
    "# GarageType       81  0.055479\n",
    "# GarageYrBlt      81  0.055479\n",
    "# GarageFinish     81  0.055479\n",
    "# GarageQual       81  0.055479\n",
    "# BsmtExposure     38  0.026027\n",
    "# BsmtFinType2     38  0.026027\n",
    "# BsmtFinType1     37  0.025342\n",
    "# BsmtCond         37  0.025342\n",
    "# BsmtQual         37  0.025342\n",
    "# MasVnrArea        8  0.005479\n",
    "# MasVnrType        8  0.005479\n",
    "# Electrical        1  0.000685\n",
    "# Utilities         0  0.000000\n",
    "\n",
    "\n",
    "\n",
    "#print(df.columns[df.isnull().any()])\n",
    "#'LotFrontage', 'Alley', 'MasVnrType', 'MasVnrArea', 'BsmtQual',\n",
    "#       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "#       'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
    "#       'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence',\n",
    "#       'MiscFeature'\n",
    "input_missing_value(df)\n",
    "\n",
    "\n",
    "#print(df_test.columns[df_test.isnull().any()])\n",
    "#Index(['MSZoning', 'LotFrontage', 'Alley', 'Utilities', 'Exterior1st',\n",
    "#       'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond',\n",
    "#       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
    "#      'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n",
    "#       'BsmtHalfBath', 'KitchenQual', 'Functional', 'FireplaceQu',\n",
    "#      'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea',\n",
    "#       'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature',\n",
    "#       'SaleType'],\n",
    "\n",
    "input_missing_value(df_test)\n",
    "\n",
    "\n",
    "#Valores numericos que continham NA sao detectados como String. Assim, depois que removemos o NA temos que setar corretamente \n",
    "#o tipo \n",
    "df_test.BsmtFullBath = df_test.BsmtFullBath.astype(\"int64\")\n",
    "df_test.BsmtHalfBath = df_test.BsmtHalfBath.astype(\"int64\")\n",
    "df_test.GarageCars = df_test.GarageCars.astype(\"int64\")\n",
    "df_test.GarageArea = df_test.GarageArea.astype(\"int64\")\n",
    "\n",
    "print(df.shape)\n",
    "print(df_test.shape)\n",
    "print(df.dtypes)\n",
    "print(\"Null values treino \\n\", df.columns[df.isnull().any()])\n",
    "print(\"Null values test \\n\", df_test.columns[df_test.isnull().any()])\n",
    "\n",
    "########################End dealing with missing values\n",
    "\n",
    "\n",
    "# The OneHotEncoder converts features represented as numeric codes (so they are values that can't be ordered)\n",
    "#to their binary representation\n",
    "#enc = preprocessing.OneHotEncoder() \n",
    "#df = enc.fit_transform(df)\n",
    "\n",
    "\n",
    "########################Tratando campos nominais\n",
    "\n",
    "vec = DictVectorizer()\n",
    "aux = np.asmatrix(vec.fit_transform(df.transpose().to_dict().values()).toarray())\n",
    "\n",
    "data_train = pd.DataFrame(aux,columns=vec.feature_names_)\n",
    "#data_train = pd.get_dummies(df)\n",
    "\n",
    "\n",
    "data_train.to_csv('train_no_categorical.csv')\n",
    "\n",
    "print(\"New shape train:\" , np.shape(data_train))\n",
    "print(\"Indice da coluna SalePrice no novo dataset\" , data_train.columns.get_loc('SalePrice'))\n",
    "\n",
    "################################################# Base de teste\n",
    "\n",
    "vec = DictVectorizer()\n",
    "aux_test = vec.fit_transform(df_test.transpose().to_dict().values()).toarray()\n",
    "data_test = pd.DataFrame(aux_test,columns=vec.feature_names_)\n",
    "#data_test = pd.get_dummies(df_test)\n",
    " \n",
    "print(\"New shape test:\" , np.shape(data_test))\n",
    "\n",
    "data_test.to_csv('test_no_categorical.csv')\n",
    "\n",
    "\n",
    "print(\"Colunas que existem apenas teste : \" , data_test.columns.difference(data_train.columns))\n",
    "print(\"Colunas que existem apenas treino : \" , data_train.columns.difference(data_test.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      1445.000000\n",
      "mean     181043.215225\n",
      "std       79195.218195\n",
      "min       34900.000000\n",
      "25%      130000.000000\n",
      "50%      163000.000000\n",
      "75%      214000.000000\n",
      "max      755000.000000\n",
      "Name: SalePrice, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAKvCAYAAAB+h+QfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHb1JREFUeJzt3XGM33d93/HXJ7+7+MwlYKyYDOKG\nbB1UP+s0ic2aNrC23TKRskRapE6kp67K5lNC0fjJVZBMkt8fLUJmwhPRLDMtiubbFlH/lqjrMjTK\nWBG/qjrKxpylmlwum9KitNdlNKmxSo6efWe++yOJ1YNAnN9d/M3v83s8pCj46/P39/7DPPny+X2/\nn29pmiYA1OOatgcAYGcJO0BlhB2gMsIOUBlhB6iMsANURtgBKiPsAJURdoDKTLXxoTfccENzyy23\ntPHRAGPrySeffKFpmn2v9XOthP2WW27JmTNn2vhogLFVSnn2Sn7OUgxAZYQdoDLCDlAZYQeojLAD\nVEbYASoj7ACVEXaAygg7QGWEHaAywg5QGWEHqIywA1RG2AEqI+wAlRF2gMoIO0BlhB2gMsIOUBlh\nB6iMsANURtgBKiPsAJURdoDKCDtAZYQdkgwGg8zNzaXT6WRubi6DwaDtkWBkU20PAG0bDAbp9/s5\ndepUDh06lOXl5SwuLiZJFhYWWp4OXr/SNM1V/9CDBw82Z86cueqfC69mbm4uJ0+ezPz8/OVjw+Ew\nvV4vZ8+ebXEy2KqU8mTTNAdf8+eEnUnX6XSyvr6e6enpy8c2NjYyMzOTS5cutTgZbHWlYbfGzsTr\ndrtZXl7ecmx5eTndbreliWB7hJ2J1+/3s7i4mOFwmI2NjQyHwywuLqbf77c9GozEl6dMvFe+IO31\nellZWUm3282xY8d8ccrYssYOMCasscPr4D52amIphonnPnZqYymGiec+dsaF+9jhCrmPnXFhjR2u\nkPvYqY2wM/Hcx05tfHnKxHMfO7Wxxg4wJqyxA0woYQeojLADVEbYASoj7ACVEXaAygg7QGWEHaAy\nwg5QGWEHqIywA1RG2AEqI+wAlRF2gMoIO0BlhB2gMsIOUBlhB6iMsANURtgBKiPsAJURdoDKCDtA\nZYQdoDLCDlAZYQeojLADVEbYASoj7ACVEXaAygg7QGWEHaAywg5QGWEHqIywA1RG2AEqI+wAlRF2\ngMoIO0BlhB2gMsIOUBlhB6iMsANURtgBKiPsAJURdoDKCDtAZYQdoDLCDlAZYQeojLADVEbYASoj\n7ACVEXaAygg7QGWEHaAywg5QGWEHqIywA1RG2AEqI+wAlRF2gMoIO0BlhB2gMsIOUJkdCXspZU8p\n5VdLKU+XUlZKKX9zJ84LwOs3tUPnOZHkvzRN8w9LKdcmecsOnReA12nbYS+lvDXJ30ryj5OkaZqL\nSS5u97wAjGYnlmL+UpLnk/ybUspTpZR/XUqZ3YHzAjCCnQj7VJK/muRfNU3zviRrSe7/wR8qpdxb\nSjlTSjnz/PPP78DHAvBqdiLsq0lWm6b57y//+lfzUui3aJrmkaZpDjZNc3Dfvn078LEAvJpth71p\nmv+X5A9LKT/18qFbk3xzu+cFYDQ7dVdML8mvvHxHzO8n+Sc7dF4AXqcdCXvTNL+T5OBOnAuA7fHk\nKUBlhB2gMsIOUBlhB6iMsANURtgBKiPsAJURdoDKCDtAZYQdoDLCDlAZYQeojLADVEbYASoj7ACV\nEXaAygg7QGWEHZIMBoPMzc2l0+lkbm4ug8Gg7ZFgZDv1zlMYW4PBIP1+P6dOncqhQ4eyvLycxcXF\nJMnCwkLL08HrV5qmueofevDgwebMmTNX/XPh1czNzeXkyZOZn5+/fGw4HKbX6+Xs2bMtTgZblVKe\nbJrmNd8vLexMvE6nk/X19UxPT18+trGxkZmZmVy6dKnFyWCrKw27NXYmXrfbzfLy8pZjy8vL6Xa7\nLU0E2yPsTLx+v5/FxcUMh8NsbGxkOBxmcXEx/X6/7dFgJL48ZeK98gVpr9fLyspKut1ujh075otT\nxpY1doAxYY0dYEIJO0BlhB2gMsIOsaUAdXFXDBPPlgLUxl0xTDxbCjAubCkAV8iWAowLtzvCFbKl\nALURdiaeLQWojS9PmXi2FKA21tgBxoQ1doAJJewAlRF2gMoIO0BlhB2gMsIOUBlhB6iMsANURtgB\nKiPsAJURdoDKCDtAZYQdoDLCDlAZYQeojLADVEbYIclgMMjc3Fw6nU7m5uYyGAzaHglG5tV4TLzB\nYJB+v59Tp07l0KFDWV5ezuLiYpJ4PR5jyavxmHhzc3M5efJk5ufnLx8bDofp9Xo5e/Zsi5PBVlf6\najxhZ+J1Op2sr69nenr68rGNjY3MzMzk0qVLLU4GW3nnKVyhbreb5eXlLceWl5fT7XZbmgi2R9iZ\neP1+P4uLixkOh9nY2MhwOMzi4mL6/X7bo8FIfHnKxHvlC9Jer5eVlZV0u90cO3bMF6eMLWvsAGPC\nGjvAhBJ2gMoIO0BlhB2gMsIOUBlhB6iMsANURtgBKiPsAJURdoDKCDtAZYQdoDLCDlAZYQeojLBD\nXnqh9dzcXDqdTubm5jIYDNoeCUYm7Ey8wWCQI0eOZG1tLU3TZG1tLUeOHBF3xpawM/GOHj2aTqeT\npaWlXLhwIUtLS+l0Ojl69Gjbo8FIhJ2Jt7q6mkcffTTz8/OZnp7O/Px8Hn300ayurrY9GoxE2AEq\nI+xMvP379+fuu+/OcDjMxsZGhsNh7r777uzfv7/t0WAkws7EO378eDY3N3P48OHMzMzk8OHD2dzc\nzPHjx9seDUYi7Ey8hYWFnDhxIrOzs0mS2dnZnDhxIgsLCy1PBqMpTdNc9Q89ePBgc+bMmav+uQDj\nrJTyZNM0B1/r51yxA1RG2AEqI+wAlRF2gMoIO0BlhB2gMsIOsW0vdZlqewBo22AwSL/fz6lTp3Lo\n0KEsLy9ncXExSTykxFjygBITb25uLidPnsz8/PzlY8PhML1eL2fPnm1xMtjqSh9QEnYmXqfTyfr6\neqanpy8f29jYyMzMTC5dutTiZLCVJ0/hCnW73SwvL285try8nG6329JEsD3CzsTr9/tZXFzcsm3v\n4uJi+v1+26PBSHx5ysR75QvSXq+XlZWVdLvdHDt2zBenjC1r7ABjwho7wIQSdoDKCDtAZYQdoDLC\nDlAZYQeojLADVEbYASoj7ACVEXaAygg7QGWEHaAywg5QGWEHqIywA1RG2AEqI+wAlRF2gMoIO0Bl\nhB2gMsIOUBlhB6iMsEOSwWCQubm5dDqdzM3NZTAYtD0SjGyq7QGgbYPBIP1+P6dOncqhQ4eyvLyc\nxcXFJMnCwkLL08Hrt2NX7KWUTinlqVLKf96pc8LVcOzYsZw6dSrz8/OZnp7O/Px8Tp06lWPHjrU9\nGoxkJ5dijiRZ2cHzwVWxsrKSQ4cObTl26NChrKz468x42pGwl1L2J7k9yb/eifPB1dTtdrO8vLzl\n2PLycrrdbksTwfbs1BX7v0hyNMn3d+h8cNX0+/0sLi5mOBxmY2Mjw+Ewi4uL6ff7bY8GI9n2l6el\nlDuS/HHTNE+WUv7Oj/m5e5PcmyQ333zzdj8WdswrX5D2er2srKyk2+3m2LFjvjhlbJWmabZ3glL+\nWZKfT7KZZCbJW5P8WtM0/+hH/ZmDBw82Z86c2dbnAkyaUsqTTdMcfK2f2/ZSTNM0DzRNs79pmluS\n/GySr/64qAPwxvKAEkBldvQBpaZpfjPJb+7kOQF4fVyxA1RG2AEqI+wQm4BRF5uAMfFsAkZttn0f\n+yjcx86bydzcXE6ePJn5+fnLx4bDYXq9Xs6ePdviZLDVld7HLuxMvE6nk/X19UxPT18+trGxkZmZ\nmVy6dKnFyWCrq/aAEow7m4BRG2Fn4tkEjNr48pSJZxMwamONHWBMWGMHmFDCDlAZYQeojLADVEbY\nASoj7ACVEXaAygg7QGWEHWI/duoi7Ey8wWCQI0eOZG1tLU3TZG1tLUeOHBF3xpawM/GOHj2aTqeT\npaWlXLhwIUtLS+l0Ojl69Gjbo8FIhJ2Jt7q6mkcffTTz8/OZnp7O/Px8Hn300ayurrY9GoxE2AEq\nI+xMvP379+fuu+/esh/73Xffnf3797c9GoxE2Jl4x48fz+bmZg4fPpyZmZkcPnw4m5ubOX78eNuj\nwUiEnYm3sLCQEydOZHZ2NkkyOzubEydOeNEGY8uLNgDGhBdtAEwoYQeojLADVEbYIfaKoS5TbQ8A\nbRsMBun3+zl16lQOHTqU5eXlLC4uJok7YxhL7oph4s3NzeXkyZOZn5+/fGw4HKbX6+Xs2bMtTgZb\nXeldMcLOxOt0OllfX8/09PTlYxsbG5mZmcmlS5danAy2crsjXKFut5tPfvKTW9bYP/nJT6bb7bY9\nGoxE2Jl48/Pz+cxnPpPDhw/nu9/9bg4fPpzPfOYzW5ZmYJwIOxNvOBzmE5/4RJaWlnL99ddnaWkp\nn/jEJzIcDtseDUZijZ2JZ42dcWGNHa5Qt9vN8vLylmPLy8vW2Blbws7E6/f7WVxc3LIf++LiYvr9\nftujwUg8oMTEW1hYyG//9m/nQx/6UC5cuJBdu3blnnvu8XASY8sVOxNvMBjkscceyzvf+c6UUvLO\nd74zjz32mG0FGFvCzsQ7evRoLl68mCQppSRJLl68mKNHj7Y5FoxM2Jl4q6ur2b17d5aWlrK+vp6l\npaXs3r07q6urbY8GIxF2SHLfffdlfn4+09PTmZ+fz3333df2SDAyYYckDz300Ja7Yh566KG2R4KR\nuSuGibd///7LWwn8wR/8QW6++eb82Z/9Wfbv39/2aDASV+xMvOPHj+faa69NkrzyJPa1116b48eP\ntzkWjEzYmXgLCwu566678txzz6Vpmjz33HO566673MfO2BJ2Jt5gMMgXv/jFfOlLX8rFixfzpS99\nKV/84hfdx87YsgkYE88blBgXNgGDK7SyspLV1dUtL9pYXV3NyspK26PBSISdifeud70rvV4va2tr\nSZK1tbX0er28613vankyGI2wM/G+973v5cUXX0yv18t3v/vd9Hq9vPjii/ne977X9mgwEmFn4p07\ndy633357HnzwwczOzubBBx/M7bffnnPnzrU9GoxE2CHJN77xjS13xXzjG99oeyQYmbAz8aampnLh\nwoUtxy5cuJCpKQ9mM578zWXiXbp0KVNTUzl8+HCeffbZvPvd787U1JT3nTK2XLEz8Q4cOJB77703\ns7OzKaVkdnY29957bw4cOND2aDASYWfi9fv9nD59OidPnsz6+npOnjyZ06dPe+cpY8tSDBPPO0+p\njSt2Jp69YqiNvWKYeHNzc7nzzjvzxBNPZGVlJd1u9/Kv7RXDm8mV7hVjKYaJ981vfjNra2tZWlrK\noUOHsry8fPkOGRhHws7Eu/baa/OBD3wgvV7v8hX7Bz7wgTz33HNtjwYjscbOxLtw4UIee+yxHD58\n+PIr8h577LEfemgJxoWwM/F27dqVu+66K0tLS7n++uuztLSUu+66K7t27Wp7NBiJsDPxLl68mK99\n7Wtb7mP/2te+losXL7Y9GozEGjsT78CBA7nzzju3rLH/3M/9XJ544om2R4ORuGJn4nnylNoIOxNv\nYWEh73nPe3Lrrbfm2muvza233pr3vOc9njxlbAk7E6/X6+UrX/lKbrzxxlxzzTW58cYb85WvfCW9\nXq/t0WAkws7Ee/jhh7Nnz56cPn066+vrOX36dPbs2ZOHH3647dFgJMLOxNvc3MznP//5zM/PZ3p6\nOvPz8/n85z+fzc3NtkeDkQg7JD+0J4w9Yhhnbndk4u3duzf3339/Op1OfuEXfiEPP/xw7r///uzd\nu7ft0WAkrtiZeJ/73Oeya9eufPzjH8/s7Gw+/vGPZ9euXfnc5z7X9mgwEmGH5IfW062vM86EnYl3\nzz33ZGNjIx/96Edz/vz5fPSjH83GxkbuueeetkeDkXjRBhOvlJIDBw7k937v9y6/Gu8nf/In881v\nfjNt/PcDfpQrfdGGK3ZI8vTTT+fTn/501tbW8ulPfzpPP/102yPByIQdkkxNTeV973tfpqen8773\nvS9TU24YY3z52wt5aeven/mZn8n58+ezZ88eW/Yy1lyxM/F27dqV9773vTl//nyapsn58+fz3ve+\n14s2GFvCzsS755578swzz+Qd73hHkuQd73hHnnnmGXfFMLaEnYn3/ve/P51OJ9/+9reTJN/+9rfT\n6XTy/ve/v+XJYDTCzsT72Mc+ls3Nzdx4440ppeTGG2/M5uZmPvaxj7U9GoxE2Jl4586dy549ezIY\nDHLhwoUMBoPs2bMn586da3s0GImwQ5IPfvCD6fV6mZmZSa/Xywc/+MG2R4KRCTskefzxx/PCCy+k\naZq88MILefzxx9seCUYm7Ey8Ukqapsnzzz+/5d+llLZHg5EIOxPvlf1gvv/972/5t31iGFfCDsnl\nu2GSXL47BsaVsENeevp09+7dKaVk9+7dnjplrNkrBpKsr69ndXU1TdNkdXXVizYYa67Y4WWvxFzU\nGXfCDi97ZV3d+jrjTtghSafTuXwXTNM06XQ6LU8EoxN2yEu3OH72s5/N2tpaPvvZz16+5RHGkXee\nMvFKKZmamkopJRsbG5menk7TNNnc3HQvO28q3nkKr8Pm5mauu+66JMl1113nC1TGmtsdmXhTU1Pp\ndDp58cUXkyQvvvhidu3alUuXLrU8GYzGFTsT79KlS7n++utz00035ZprrslNN92U66+/XtgZW8LO\nxDtw4EA+8pGPZHZ2NkkyOzubj3zkIzlw4EDLk8FoLMUw8fr9fo4cOZLZ2dk0TZO1tbU88sgjOXHi\nRNujwUiEHfLSlgLnz59P0zT5oz/6o8zMzLQ9EozMUgwT7+jRo5fX1v/8v48ePdr2aDASYWfira6u\nZvfu3VlaWsr6+nqWlpaye/furK6utj0ajETYIcl9992X+fn5TE9PZ35+Pvfdd1/bI8HIhB2SPPTQ\nQxkOh9nY2MhwOMxDDz3U9kgwMl+eMvH279+fP/mTP8ltt912eUuBqamp7N+/v+3RYCSu2Jl4d955\nZy5cuJC9e/cmSfbu3ZsLFy7kzjvvbHkyGI2wM/GGw2EeeOCB3HDDDbnmmmtyww035IEHHshwOGx7\nNBiJ3R2ZeJ1OJ+vr65menr58bGNjIzMzM7YV4E3F7o5whbrdbj784Q9nZmYmpZTMzMzkwx/+cLrd\nbtujwUiEnYl300035Yknnshb3vKWXHPNNXnLW96SJ554IjfddFPbo8FIhJ2J99WvfjXXXXdd3va2\nt6VpmrztbW/Lddddl69+9attjwYjEXYm3ubmZh5//PF861vfyve///1861vfyuOPP+5lG4wtYYck\nn/rUp7assX/qU59qeyQYmbAz8Xbt2pWvf/3rue222/L888/ntttuy9e//vXs2rWr7dFgJJ48ZeJd\nunQp09PT+cIXvpB9+/YlSaanp93qyNhyxc7E29zczMzMzOX72KenpzMzM2ONnbG17bCXUn6ilDIs\npayUUn63lHJkJwaDq+3LX/5yLl68mC9/+cttjwLbshNX7JtJPt40TTfJ30jyT0spXhbJWFlbW8tT\nTz2VjY2NPPXUU1lbW2t7JBjZtsPeNM1zTdP8z5f/83eTrCTxZAdj5Y477siDDz6Y2dnZPPjgg7nj\njjvaHglGtqN7xZRSbknyW0nmmqb50x/4vXuT3JskN99881979tlnd+xz4UcppVyVz2ljzyUmz1Xf\nK6aUcl2S/5DkF38w6knSNM0jTdMcbJrm4Ct3HsAbrWma1/zn9OnT2bdvX2655ZYkyS233JJ9+/bl\n9OnTV/TnRZ03mx0JeyllOi9F/Veapvm1nTgnXC0LCws5ceJEZmdnkySzs7M5ceJEFhYWWp4MRrPt\npZjy0v/X/XdJzjVN84tX8mds28ubVSnFFThvWldzKeYDSX4+yd8tpfzOy//8/R04LwAj2PaTp03T\nLCe5Ot9QAfCaPHkKUBlhB6iMsANURtgBKiPsAJURdoDKCDtAZYQdoDLCDlAZYQeojLADVEbYASoj\n7ACVEXaAygg7QGWEHaAywg5QGWEHqIywA1RG2AEqI+wAlRF2gMoIO0BlhB2gMsIOUBlhB6iMsANU\nRtgBKiPsAJURdoDKCDtAZYQdoDLCDlAZYQeojLADVEbYASoj7ACVEXaAygg7QGWEHaAywg5QGWEH\nqIywA1RG2AEqI+wAlRF2gMoIO0BlhB2gMsIOUBlhB6iMsANURtgBKiPsAJURdoDKCDtAZYQdoDLC\nDlAZYQeojLADVEbYASoj7ACVEXaAygg7QGWEHaAywg5QGWEHqIywA1RG2AEqI+wAlRF2gMoIO0Bl\nhB2gMsIOUBlhB6iMsANURtgBKiPsAJURdoDKCDtAZYQdoDLCDlAZYQeojLADVEbYASoj7ACVEXaA\nygg7QGWEHaAywg5QGWEHqIywA1RG2AEqI+wAlRF2gMoIO0BlhB2gMsIOUBlhB6jMVNsDwJXau3dv\nvvOd77zhn1NKeUPP//a3vz3nzp17Qz+DySbsjI3vfOc7aZqm7TG27Y3+Hw6wFANQGWEHqIywA1RG\n2AEqI+wAlRF2gMoIO0BlhB2gMsIOUBlhB6iMsANURtgBKiPsAJURdoDKCDtAZYQdoDLCDlAZYQeo\njLADVEbYASoj7ACV2ZGwl1J+upTyv0spz5RS7t+JcwIwmm2HvZTSSfIvk3woyYEkC6WUA9s9LwCj\n2Ykr9r+e5JmmaX6/aZqLSf59kn+wA+cFYAQ7Efabkvzhn/v16svHAGjBToS9vMqx5od+qJR7Syln\nSilnnn/++R34WABezU6EfTXJT/y5X+9P8n9/8IeapnmkaZqDTdMc3Ldv3w58LACvZifC/j+SvKeU\n8hdLKdcm+dkkX9iB8wIwgqntnqBpms1SyseSfDlJJ8lS0zS/u+3JABjJtsOeJE3T/HqSX9+JcwGw\nPZ48BaiMsANURtgBKiPsAJURdoDKCDtAZYQdoDLCDlAZYQeojLADVGZHthSAq6H5pbcmv/y2tsfY\ntuaX3tr2CFRO2Bkb5ZN/mqb5oa3+x04pJc0vtz0FNbMUA1AZYQeojLADVEbYASoj7ACVEXaAygg7\nQGWEHaAywg5QGWEHqIywA1RG2AEqI+wAlRF2gMoIO0BlhB2gMsIOUBlhB6iMsANURtgBKiPsAJUR\ndoDKCDtAZYQdoDLCDlCZqbYHgNejlNL2CNv29re/ve0RqJywMzaapnnDP6OUclU+B95IlmIAKiPs\nAJURdoDKCDtAZYQdoDLCDlAZYQeojLADVEbYASoj7ACVEXaAygg7QGWEHaAywg5QGWEHqIywA1RG\n2AEqI+wAlRF2gMoIO0BlhB2gMsIOUBlhB6iMsANURtgBKiPsAJURdoDKCDtAZYQdoDLCDlAZYQeo\njLADVEbYASoj7ACVEXaAygg7QGWEHaAywg5QGWEHqIywA1RG2AEqI+wAlRF2gMoIO0BlhB2gMsIO\nUBlhB6iMsANURtgBKiPsAJURdoDKCDtAZYQdoDLCDlAZYQeojLADVEbYASoj7ACVEXaAygg7QGWE\nHaAywg5QGWEHqIywA1RG2AEqI+wAlRF2gMoIO0BlhB2gMsIOUBlhB6iMsANURtgBKiPsAJURdoDK\nCDtAZabaHgDeSKWUq/JnmqZ53X8G3ijCTtUEl0lkKQagMsIOUBlhB6iMsANUZlthL6X881LK06WU\n/1VK+Y+llD07NRgAo9nuFftvJJlrmuavJPk/SR7Y/kgAbMe2wt40zX9tmmbz5V/+tyT7tz8SANux\nk2vsh5N8aQfPB8AIXvMBpVLKV5L8hVf5rX7TNP/p5Z/pJ9lM8is/5jz3Jrk3SW6++eaRhgXgtb1m\n2Jum+Xs/7vdLKXcnuSPJrc2PecyvaZpHkjySJAcPHvQ4IMAbZFtbCpRSfjrJJ5L87aZpvrczIwGw\nHdtdY/9ckuuT/EYp5XdKKQ/vwEwAbMO2rtibpvnLOzUIADvDk6cAlRF2gMoIO0BlhB2gMsIOUBlh\nB6iMsANURtgBKiPsAJURdoDKCDtAZYQdoDLCDlAZYQeojLADVKb8mLfZvXEfWsrzSZ696h8Mr+2G\nJC+0PQT8CO9ummbfa/1QK2GHN6tSypmmaQ62PQdsh6UYgMoIO0BlhB22eqTtAWC7rLEDVMYVO0Bl\nhB2SlFKWSil/XEo52/YssF3CDi/5t0l+uu0hYCcIOyRpmua3kpxrew7YCcIOUBlhB6iMsANURtgB\nKiPskKSUMkjy9SQ/VUpZLaUstj0TjMqTpwCVccUOUBlhB6iMsANURtgBKiPsAJURdoDKCDtAZYQd\noDL/H6zcxqly4AroAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f41e715c550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9JLUOINekhpn0EtS4wx6SWqcQS9Jjft/LrlT7CnJ2MUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f41e715cc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noJekxhn0ktS4/wWSZRZc2oBixQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f42144469e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f41e7007358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNc6gl6TGGfSS1DiDXpIaZ9BLUuP+D3S2o9sqglNlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f41e6f49208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6pxBL0md+3/g/Ko1eQr7mAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f41e6db9be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "print(data_train.SalePrice.describe())\n",
    "\n",
    "saleprice_scaled = preprocessing.StandardScaler().fit_transform((data_train['SalePrice'][:,np.newaxis]));\n",
    "fig = plt.figure(1, figsize=(6, 12))\n",
    "#ax = fig.add_subplot(111)\n",
    "#ax.boxplot(saleprice_scaled)\n",
    "plt.boxplot(saleprice_scaled,showfliers=True)\n",
    "\n",
    "plt.figure()\n",
    "x = plt.hist(data_train['SalePrice'],bins=50)\n",
    "\n",
    "plt.figure()\n",
    "saleprice_log = np.log(data_train['SalePrice'])\n",
    "x = plt.hist(saleprice_log,bins=50)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "x = plt.hist(data_train['LotArea'],bins=50)\n",
    "\n",
    "plt.figure()\n",
    "saleprice_log = np.log(data_train['LotArea'])\n",
    "x = plt.hist(saleprice_log,bins=50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "x = plt.hist(data_train['GarageCars'],bins=50)\n",
    "\n",
    "# plt.figure()\n",
    "# saleprice_log = np.log(data_train['GarageArea'])\n",
    "# x = plt.hist(saleprice_log,bins=50)\n",
    "\n",
    "\n",
    "#data_train['SalePrice'] = np.log1p(data_train['SalePrice'])\n",
    "data_train['OverallQual'] = np.log1p(data_train['OverallQual'])\n",
    "data_train['LotArea'] = np.log1p(data_train['LotArea'])\n",
    "\n",
    "\n",
    "data_test['OverallQual'] = np.log1p(data_test['OverallQual'])\n",
    "data_test['LotArea'] = np.log1p(data_test['LotArea'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tentativa de selecionar melhores features \n",
      "\n",
      "\n",
      "As features selecionadas com Tree-based feature selection foram: \n",
      "\n",
      "['ExterQual=TA' 'OverallQual' 'GarageCars' 'BsmtQual=Ex' 'GrLivArea'\n",
      " 'Neighborhood=NoRidge' 'FullBath' 'FireplaceQu=No' '1stFlrSF'\n",
      " 'TotalBsmtSF' '2ndFlrSF' 'TotRmsAbvGrd' 'BsmtFinSF1' 'LotArea'\n",
      " 'Fireplaces' 'BsmtQual=Gd' 'GarageType=Attchd' 'MSSubClass=60'\n",
      " 'ExterQual=Fa' 'GarageArea' 'BldgType=1Fam' 'BedroomAbvGr'\n",
      " 'BsmtExposure=Gd' 'KitchenQual=Ex' 'YearRemodAdd' 'KitchenQual=TA'\n",
      " 'BsmtFullBath']\n",
      "[[ 0.26991191  0.12667146  0.10957647  0.09799615  0.07651793  0.02271206\n",
      "   0.01753115  0.01702428  0.01424131  0.01380709  0.0132069   0.01044194\n",
      "   0.00948012  0.007616    0.00734343  0.0057867   0.0056749   0.00564212\n",
      "   0.00501449  0.00477752  0.00477482  0.00471144  0.00445187  0.0042494\n",
      "   0.00390791  0.00353439  0.00346378]]\n",
      "\n",
      " New shape train apos Tree-based feature selection: (1445, 24)\n",
      "\n",
      " Fim tentativa selecionar melhores features \n",
      "\n",
      "\n",
      " New shape test apos Tree-based feature selection: (1459, 24)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Tentativa de selecionar melhores features \\n\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "#Removing features with low variance\n",
    "#print(\"Original shape: {}\".format(np.shape(df.iloc[:,0:-1])))\n",
    "#sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "#features = sel.fit_transform(df.iloc[:,0:-1])\n",
    "#print(\"Shape apos Removing features with low variance {}\".format(np.shape(features))) #nenhuma foi selecionada \n",
    "#print(\"\\n\")\n",
    "\n",
    "#Tree-based feature selection\n",
    "y_train = (data_train['SalePrice'])\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "\n",
    "print()\n",
    "\n",
    "clf = ExtraTreesRegressor(n_estimators=20)\n",
    "clf = clf.fit(x_train,y_train)\n",
    "data = np.zeros((1,x_train.shape[1])) \n",
    "data = pd.DataFrame(data, columns=x_train.columns)\n",
    "data.iloc[0] = clf.feature_importances_\n",
    "data = data.T.sort_values(df.index[0], ascending=False).T\n",
    "\n",
    "\n",
    "print(\"As features selecionadas com Tree-based feature selection foram: \\n\")\n",
    "yyy = np.asarray((data.columns[0:27]))\n",
    "xxx = np.asarray((data.iloc[:,0:27]))\n",
    "print(yyy)\n",
    "print(xxx)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "aux = model.transform(x_train)\n",
    "\n",
    "print(\"\\n New shape train apos Tree-based feature selection: {}\".format(aux.shape))\n",
    "\n",
    "print(\"\\n Fim tentativa selecionar melhores features \\n\")\n",
    "\n",
    "\n",
    "data_train_less_features = pd.concat([pd.DataFrame(aux),pd.DataFrame(y_train)],axis=1)\n",
    "data_train_less_features.to_csv('data_train_less_features.csv')\n",
    "\n",
    "\n",
    "aux = model.transform((data_test))\n",
    "data_test_less_features = pd.DataFrame(aux)\n",
    "print(\"\\n New shape test apos Tree-based feature selection: {}\".format(aux.shape))\n",
    "data_test_less_features.to_csv('data_test_less_features.csv')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn   import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression \n",
      "Fold #1\n",
      "Fold score (RMSE): 792507042910496768.00\n",
      "Accuracy: -101813892814892254915198976.000\n",
      "Fold #2\n",
      "Fold score (RMSE): 73492366810621184.00\n",
      "Accuracy: -865784988953721866027008.000\n",
      "Fold #3\n",
      "Fold score (RMSE): 104478007166089504.00\n",
      "Accuracy: -1526623675318398248550400.000\n",
      "Fold #4\n",
      "Fold score (RMSE): 414068993786018432.00\n",
      "Accuracy: -31642084218901363142164480.000\n",
      "Fold #5\n",
      "Fold score (RMSE): 24886.34\n",
      "Accuracy: 0.901\n",
      "\n",
      " Average RMSE: 4.039399278701055e+17\n",
      "\n",
      "\n",
      "\n",
      "SGDRegressor \n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 45946.10\n",
      "Accuracy: 0.658\n",
      "Fold #2\n",
      "Fold score (RMSE): 3073325.92\n",
      "Accuracy: -1513.059\n",
      "Fold #3\n",
      "Fold score (RMSE): 1006819.61\n",
      "Accuracy: -140.770\n",
      "Fold #4\n",
      "Fold score (RMSE): 927466.92\n",
      "Accuracy: -157.751\n",
      "Fold #5\n",
      "Fold score (RMSE): 295805.78\n",
      "Accuracy: -12.941\n",
      "\n",
      " Average RMSE: 1510551.218061962\n",
      "\n",
      "\n",
      "\n",
      "Ridge \n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 30437.69\n",
      "Accuracy: 0.850\n",
      "Fold #2\n",
      "Fold score (RMSE): 26394.21\n",
      "Accuracy: 0.888\n",
      "Fold #3\n",
      "Fold score (RMSE): 33728.04\n",
      "Accuracy: 0.841\n",
      "Fold #4\n",
      "Fold score (RMSE): 56491.52\n",
      "Accuracy: 0.411\n",
      "Fold #5\n",
      "Fold score (RMSE): 24380.90\n",
      "Accuracy: 0.905\n",
      "\n",
      " Average RMSE: 36183.99701556693\n",
      "\n",
      "\n",
      "\n",
      "Lasso \n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 29098.79\n",
      "Accuracy: 0.863\n",
      "Fold #2\n",
      "Fold score (RMSE): 25800.15\n",
      "Accuracy: 0.893\n",
      "Fold #3\n",
      "Fold score (RMSE): 31471.71\n",
      "Accuracy: 0.861\n",
      "Fold #4\n",
      "Fold score (RMSE): 52445.25\n",
      "Accuracy: 0.492\n",
      "Fold #5\n",
      "Fold score (RMSE): 24440.83\n",
      "Accuracy: 0.905\n",
      "\n",
      " Average RMSE: 34207.35198656157\n",
      "\n",
      "\n",
      "\n",
      "Elastic Net \n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 66262.28\n",
      "Accuracy: 0.288\n",
      "Fold #2\n",
      "Fold score (RMSE): 66612.57\n",
      "Accuracy: 0.289\n",
      "Fold #3\n",
      "Fold score (RMSE): 72660.92\n",
      "Accuracy: 0.262\n",
      "Fold #4\n",
      "Fold score (RMSE): 62276.96\n",
      "Accuracy: 0.284\n",
      "Fold #5\n",
      "Fold score (RMSE): 66429.98\n",
      "Accuracy: 0.297\n",
      "\n",
      " Average RMSE: 66931.1510491102\n",
      "\n",
      "\n",
      " Less Features\n",
      "Linear Regression \n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 25902.91\n",
      "Accuracy: 0.873\n",
      "Fold #2\n",
      "Fold score (RMSE): 34758.10\n",
      "Accuracy: 0.815\n",
      "Fold #3\n",
      "Fold score (RMSE): 34860.93\n",
      "Accuracy: 0.840\n",
      "Fold #4\n",
      "Fold score (RMSE): 27059.70\n",
      "Accuracy: 0.858\n",
      "Fold #5\n",
      "Fold score (RMSE): 45063.83\n",
      "Accuracy: 0.698\n",
      "\n",
      " Average RMSE: 34226.73286373472\n",
      "\n",
      "\n",
      "\n",
      "SGDRegressor \n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 26128.44\n",
      "Accuracy: 0.870\n",
      "Fold #2\n",
      "Fold score (RMSE): 34807.14\n",
      "Accuracy: 0.815\n",
      "Fold #3\n",
      "Fold score (RMSE): 33159.92\n",
      "Accuracy: 0.855\n",
      "Fold #4\n",
      "Fold score (RMSE): 27036.23\n",
      "Accuracy: 0.858\n",
      "Fold #5\n",
      "Fold score (RMSE): 43647.58\n",
      "Accuracy: 0.717\n",
      "\n",
      " Average RMSE: 33555.56956801082\n",
      "\n",
      "\n",
      "\n",
      "Ridge \n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 25785.55\n",
      "Accuracy: 0.874\n",
      "Fold #2\n",
      "Fold score (RMSE): 34699.40\n",
      "Accuracy: 0.816\n",
      "Fold #3\n",
      "Fold score (RMSE): 34909.86\n",
      "Accuracy: 0.839\n",
      "Fold #4\n",
      "Fold score (RMSE): 26991.50\n",
      "Accuracy: 0.858\n",
      "Fold #5\n",
      "Fold score (RMSE): 44990.93\n",
      "Accuracy: 0.699\n",
      "\n",
      " Average RMSE: 34177.08720451123\n"
     ]
    }
   ],
   "source": [
    "#Starting making predictors\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, RidgeCV, Lasso, LassoCV, ElasticNetCV\n",
    "\n",
    "#Caso 1 - Linear Regression \n",
    "print(\"Linear Regression \")\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#Normalization\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "classifier = LinearRegression()\n",
    "kf = KFold(5, random_state=7)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "pred = []\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"SGDRegressor \\n\\n\")\n",
    "\n",
    "\n",
    "classifier = SGDRegressor()\n",
    "\n",
    "kf = KFold(5, random_state=7)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "pred = []\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Ridge \\n\\n\")\n",
    "\n",
    "\n",
    "classifier = RidgeCV()\n",
    "\n",
    "kf = KFold(5, random_state=7)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "pred = []\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Lasso \\n\\n\")\n",
    "\n",
    "\n",
    "classifier = LassoCV()\n",
    "\n",
    "kf = KFold(5, random_state=7)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "pred = []\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Elastic Net \\n\\n\")\n",
    "\n",
    "\n",
    "classifier = ElasticNetCV()\n",
    "\n",
    "kf = KFold(5, random_state=7)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "pred = []\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "\n",
    "\n",
    "###########Less features\n",
    "\n",
    "print(\"\\n\\n Less Features\")\n",
    "print(\"Linear Regression \\n\")\n",
    "#Normalization\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifierLinearRegression = LinearRegression()\n",
    "kf = KFold(5, random_state=7)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "pred = []\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "    pred = []    \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifierLinearRegression = classifierLinearRegression.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifierLinearRegression.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifierLinearRegression.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "  \n",
    "#Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# Write the cross-validated prediction\n",
    "pred = []\n",
    "pred = np.array(pred)\n",
    "pred = classifierLinearRegression.predict(scaler.transform(data_test_less_features))\n",
    "pd.DataFrame({'Id': range(1461,2920), 'SalePrice': pred}).to_csv('pred_LinearRegression.csv', index =False)  \n",
    "\n",
    "#result = pd.DataFrame(pred,columns=['SalePrice'], index=range(1461,2920))\n",
    "#result.to_csv('pred_LinearRegression.csv', columns=['SalePrice'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"SGDRegressor \\n\\n\")\n",
    "\n",
    "classifier = SGDRegressor()\n",
    "\n",
    "kf = KFold(5, random_state=7)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "pred = []\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Ridge \\n\\n\")\n",
    "\n",
    "\n",
    "classifier = RidgeCV()\n",
    "\n",
    "kf = KFold(5, random_state=7)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "pred = []\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Fold #1\n"
     ]
    }
   ],
   "source": [
    "#Caso 3 - SVM\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import NuSVR\n",
    "\n",
    "print(\"SVM\")\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#Normalization\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train = scaler.transform((x_train))\n",
    "x_train = np.ascontiguousarray(x_train)\n",
    "\n",
    "\n",
    "classifier = SVR(kernel='linear', C=1e4) #34761.27693615821\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "\n",
    "# The mean squared error\n",
    "#pred = classifier.predict(x_test_scaled)\n",
    "#score = metrics.mean_squared_error(y_test, pred)\n",
    "#print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "\n",
    "# Evaluate success using accuracy\n",
    "#print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "###########Less features\n",
    "print(\"\\n\\n Less features \\n\")\n",
    "#Normalization\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train = scaler.transform((x_train))\n",
    "x_train = np.ascontiguousarray(x_train)\n",
    "\n",
    "\n",
    "#classifier = SVR(kernel='rbf', C=1e3, gamma=0.1) #66483.84692815947\n",
    "classifierSVR = SVR(kernel='linear', C=1e4) #34761.27693615821\n",
    "#classifier = SVR(kernel='poly', C=1e3, degree=3) #86747.4465877091\n",
    "#classifier = NuSVR(C=1e3) #57249.1589623674\n",
    "\n",
    "kf = KFold(5, random_state=7)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifierSVR = classifierSVR.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifierSVR.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifierSVR.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "    \n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# Write the cross-validated prediction\n",
    "pred = []\n",
    "pred = np.array(pred)\n",
    "pred = classifierSVR.predict(scaler.transform(data_test_less_features))\n",
    "pd.DataFrame({'Id': range(1461,2920), 'SalePrice': pred}).to_csv('pred_SVR.csv', index =False)  \n",
    "\n",
    "#result = pd.DataFrame(pred,columns=['SalePrice'], index=range(1461,2920))\n",
    "#result.to_csv('pred_SVR.csv', columns=['SalePrice'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN MLPRegressor\n",
      "Fold #1\n",
      "Fold score (RMSE): 35128.84\n",
      "Accuracy: 0.755\n",
      "Fold #2\n",
      "Fold score (RMSE): 51551.83\n",
      "Accuracy: 0.566\n",
      "Fold #3\n",
      "Fold score (RMSE): 39832.25\n",
      "Accuracy: 0.762\n",
      "Fold #4\n",
      "Fold score (RMSE): 50935.52\n",
      "Accuracy: 0.633\n",
      "Fold #5\n",
      "Fold score (RMSE): 42441.85\n",
      "Accuracy: 0.715\n",
      "\n",
      " Average RMSE: 44438.66231575653\n",
      "\n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 28413.47\n",
      "Accuracy: 0.847\n",
      "Fold #2\n",
      "Fold score (RMSE): 37708.84\n",
      "Accuracy: 0.783\n",
      "Fold #3\n",
      "Fold score (RMSE): 36068.39\n",
      "Accuracy: 0.828\n",
      "Fold #4\n",
      "Fold score (RMSE): 29272.77\n",
      "Accuracy: 0.834\n",
      "Fold #5\n",
      "Fold score (RMSE): 49299.61\n",
      "Accuracy: 0.638\n",
      "\n",
      " Average RMSE: 36925.75352703189\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Shuffle\n",
    "print(\"NN MLPRegressor\")\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#Normalization\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10,4,2), random_state=1)\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# The mean squared error\n",
    "#pred = classifier.predict(x_test_scaled)\n",
    "#score = metrics.mean_squared_error(y_test, pred)\n",
    "#print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "\n",
    "# Evaluate success using accuracy\n",
    "#print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "###########Less features\n",
    "print(\"\\n\\n\")\n",
    "#Normalization\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(8,2), random_state=1)\n",
    "kf = KFold(5, random_state=7)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests\n",
      "Mean squared error using all features and no normalization: 29465.849040071567\n",
      "Accuracy using all features and no normalization: 0.896\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Average RMSE using all features, cross validation and normalizing: 29532.091564345068\n",
      "\n",
      " oob score using all features cross validation and normalizing: 0.8523470566286862\n",
      "\n",
      "\n",
      " Less features \n",
      "\n",
      "\n",
      "Mean squared error using less features and no normalization: 32336.686767462506\n",
      "Accuracy using less features and no normalization: 0.871\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Average RMSE (corss) less features, normalizing: 31173.340692695157\n",
      "\n",
      " oob score (cross) less features, normalizing: 0.8486583626088018\n"
     ]
    }
   ],
   "source": [
    "##Random Forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Shuffle\n",
    "print(\"Random Forests\")\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_train.drop('SalePrice',axis=1), data_train['SalePrice'], \n",
    "                                                    test_size=0.20, random_state=42)\n",
    "\n",
    "classifierAllFeatures = RandomForestRegressor(n_estimators=60,oob_score=True)\n",
    "\n",
    "classifierAllFeatures.fit(x_train, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifierAllFeatures.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error using all features and no normalization: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy using all features and no normalization: %.3f\" % classifierAllFeatures.score(X=x_test,y=y_test))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train = scaler.transform((x_train))\n",
    "\n",
    "#classifier = RandomForestRegressor(n_estimators=1000,oob_score=True)\n",
    "\n",
    "kf = KFold(5, random_state=7)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    #print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifierAllFeatures.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifierAllFeatures.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    #print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    #print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE using all features, cross validation and normalizing: {}\".format(score))    \n",
    "print(\"\\n oob score using all features cross validation and normalizing: {}\".format(classifierAllFeatures.oob_score_))    \n",
    "\n",
    "# Write the cross-validated prediction\n",
    "pred = []\n",
    "pred = np.array(pred,dtype='int64')\n",
    "pred = classifierAllFeatures.predict(scaler.transform(data_test))\n",
    "pd.DataFrame({'Id': range(1461,2920), 'SalePrice': pred}).to_csv('pred_RF_full_features.csv', index =False)  \n",
    "\n",
    "#result = pd.DataFrame(pred,columns=['SalePrice'], index=range(1461,2920))\n",
    "#result.to_csv('pred_RF_full_features.csv', columns=['SalePrice'])\n",
    "\n",
    "###########Less features\n",
    "print(\"\\n\\n Less features \\n\\n\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_train_less_features.drop('SalePrice',axis=1), \n",
    "                                    data_train_less_features['SalePrice'], test_size=0.20, random_state=42)\n",
    "\n",
    "classifierRF_lessFeatures = RandomForestRegressor(n_estimators=60,oob_score=True)\n",
    "\n",
    "classifierRF_lessFeatures.fit(x_train, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifierRF_lessFeatures.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error using less features and no normalization: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy using less features and no normalization: %.3f\" % classifierRF_lessFeatures.score(X=x_test,y=y_test))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train = scaler.transform((x_train))\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=7)    \n",
    "\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "pred = []\n",
    "\n",
    "#classifierRandomForestRegressor = RandomForestRegressor(n_estimators=1000,oob_score=True,max_depth=3)\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    #print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifierRF_lessFeatures.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifierRF_lessFeatures.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    #print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    #print(\"Accuracy: %.3f\" % classifierRandomForestRegressor.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE (corss) less features, normalizing: {}\".format(score))    \n",
    "print(\"\\n oob score (cross) less features, normalizing: {}\".format(classifierRF_lessFeatures.oob_score_))    \n",
    "\n",
    "\n",
    "# Write the cross-validated prediction\n",
    "pred = []\n",
    "pred = np.array(pred,dtype='int64')\n",
    "pred = classifierRF_lessFeatures.predict(scaler.transform(data_test_less_features))\n",
    "pd.DataFrame({'Id': range(1461,2920), 'SalePrice': pred}).to_csv('pred_RF_less_features.csv', index =False)  \n",
    "\n",
    "#result = pd.DataFrame(pred,columns=['SalePrice'], index=range(1461,2920))\n",
    "#result.to_csv('pred_RF_less_features.csv', columns=['SalePrice'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 26968.71918280807\n",
      "Accuracy: 0.867\n",
      "\n",
      "\n",
      "\n",
      "Mean squared error: 24902.991936161186\n",
      "Accuracy: 0.895\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "data_train_less_features = data_train_less_features.reindex(np.random.permutation(data_train_less_features.index))\n",
    "data_train_less_features.reset_index(inplace=True, drop=True)\n",
    "\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train,y_train,test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "classifierGBR = GradientBoostingRegressor(n_estimators=1100, learning_rate=0.05, \n",
    "                                               min_samples_leaf=25, min_samples_split=20, loss='huber').fit(x_train, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifierGBR.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifierGBR.score(X=x_test,y=y_test))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "data_train_less_features = data_train_less_features.reindex(np.random.permutation(data_train_less_features.index))\n",
    "data_train_less_features.reset_index(inplace=True, drop=True)\n",
    "\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train,y_train,test_size=0.20, random_state=43)\n",
    "\n",
    "classifierGBR.fit(x_train, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifierGBR.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifierGBR.score(X=x_test,y=y_test))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#save the contest result \n",
    "predGBR = []\n",
    "predGBR = np.array(pred,dtype='int64')\n",
    "predGBR = classifierGBR.predict(scaler.transform(data_test_less_features))\n",
    "pd.DataFrame({'Id': range(1461,2920), 'SalePrice': predGBR}).to_csv('pred_GBR.csv', index =False)  \n",
    "\n",
    "#result = pd.DataFrame(pred,columns=['SalePrice'], index=range(1461,2920))\n",
    "#result.to_csv('pred_GBR.csv', columns=['SalePrice'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold score (RMSE): 47722.64\n",
      "Fold #2\n",
      "Fold score (RMSE): 27376.79\n",
      "Fold #3\n",
      "Fold score (RMSE): 35460.69\n",
      "Fold #4\n",
      "Fold score (RMSE): 23509.86\n",
      "Fold #5\n",
      "Fold score (RMSE): 24637.01\n",
      "\n",
      " Average RMSE: 32997.25982834273\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.contrib.learn as learn\n",
    "import shutil \n",
    "import os\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "# Set the desired TensorFlow output level for this example\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df,target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    \n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.int32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "\n",
    "    # Get a new directory to hold checkpoints from a neural network.  This allows the neural network to be\n",
    "# loaded later.  If the erase param is set to true, the contents of the directory will be cleared.\n",
    "def get_model_dir(name,erase=False):\n",
    "    base_path = os.path.join(\".\",\"dnn\")\n",
    "    model_dir = os.path.join(base_path,name)\n",
    "    os.makedirs(model_dir,exist_ok=True)\n",
    "    if erase and len(model_dir)>4 and os.path.isdir(model_dir):\n",
    "        shutil.rmtree(model_dir,ignore_errors=True) # be careful, this deletes everything below the specified path\n",
    "    return model_dir\n",
    "\n",
    "\n",
    "#Normalization\n",
    "# y_train = ((data_train['SalePrice']))\n",
    "# x_train = (data_train.drop('SalePrice',axis=1))\n",
    "# scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "# x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "\n",
    "#Normalization\n",
    "#x_train,y_train = to_xy(data_train_less_features,\"SalePrice\")\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "#Choose an optimizer\n",
    "#opt=tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "#opt=tf.train.MomentumOptimizer(learning_rate=0.001,momentum=0.9)\n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x_train.shape[1])]\n",
    "classifierDNN = learn.DNNRegressor(\n",
    "                                    #hidden_units=[200,100, 80, 80, 50, 50, 80,80], \n",
    "                                    hidden_units=[ 80, 80, 20], \n",
    "                                   feature_columns=feature_columns,\n",
    "                                   model_dir=get_model_dir(\"dnn\",True)\n",
    "                                   #optimizer=opt\n",
    "                                  )\n",
    "\n",
    "\n",
    "kf = KFold(5, random_state=7)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    # Early stopping\n",
    "    validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    x_test_fold,\n",
    "    y_test_fold,\n",
    "    every_n_steps=500,\n",
    "    #metrics=validation_metrics,\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=400)\n",
    "        \n",
    "    classifierDNN.fit(x_train_fold, y_train_fold, monitors=[validation_monitor] ,steps=1000)\n",
    "    pred = (list(classifierDNN.predict(x_test_fold, as_iterable=True)))\n",
    "    \n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#Save the contest result\n",
    "pred = (list(classifierDNN.predict(scaler.transform(data_test_less_features),as_iterable=True)))\n",
    "#pred = list(classifierDNN.predict(scaler.transform(data_test),as_iterable=True))\n",
    "pd.DataFrame({'Id': range(1461,2920), 'SalePrice': pred}).to_csv('pred_DNN.csv', index =False)  \n",
    "#result = pd.DataFrame(pred,columns=['SalePrice'], index=range(1461,2920))\n",
    "#result.to_csv('pred_DNN.csv', columns=['SalePrice'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# Voting Ensemble for Classification\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train = scaler.transform((x_train))\n",
    "\n",
    "# estimators = []\n",
    "# estimators.append(('linear',classifierLinearRegression))\n",
    "# estimators.append(('svr',classifierSVR))\n",
    "# estimators.append(('rf',classifierRandomForestRegressor))\n",
    "\n",
    "# # # create the ensemble model\n",
    "# ensemble = VotingClassifier(estimators,voting='hard')\n",
    "# ensemble = ensemble.fit(x_train,y_train)\n",
    "# pred = []\n",
    "# pred = np.array(pred,dtype='float64')\n",
    "# pred = ensemble.predict(scaler.transform(data_test_less_features))\n",
    "# result = pd.DataFrame(pred,columns=['SalePrice'], index=range(1461,2920))\n",
    "# result.to_csv('pred_EnsembleVoting.csv', columns=['SalePrice'])\n",
    "\n",
    "\n",
    "#Emsemble via stacking\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "stregr = StackingRegressor(regressors=[classifierLinearRegression\n",
    "                                       ,classifierSVR\n",
    "                                       ,classifierRF_lessFeatures\n",
    "                                       ,classifierGBR], \n",
    "                           meta_regressor=classifierLinearRegression)\n",
    "stregr.fit(x_train,y_train)\n",
    "pred = []\n",
    "pred = np.array(pred)\n",
    "pred = stregr.predict(scaler.transform(data_test_less_features))\n",
    "pd.DataFrame({'Id': range(1461,2920), 'SalePrice': pred}).to_csv('pred_EnsembleStacker.csv', index =False)  \n",
    "\n",
    "#result = pd.DataFrame(pred,columns=['SalePrice'], index=range(1461,2920))\n",
    "#result.to_csv('pred_EnsembleStacker.csv', columns=['SalePrice'])\n",
    "\n",
    "\n",
    "#Emsemble via avereging\n",
    "dnn=[]\n",
    "#dnn = list(classifierDNN.predict(scaler.transform(data_test_less_features),as_iterable=True))\n",
    "\n",
    "final_labels = (\n",
    "                (classifierLinearRegression.predict(scaler.transform(data_test_less_features)))  \n",
    "                + (classifierSVR.predict(scaler.transform(data_test_less_features))) \n",
    "                + (classifierRF_lessFeatures.predict(scaler.transform(data_test_less_features)))\n",
    "                + (classifierGBR.predict(scaler.transform(data_test_less_features)))                 \n",
    "                #+ dnn\n",
    "               \n",
    "               ) / 4\n",
    "\n",
    "## Saving to CSV\n",
    "pd.DataFrame({'Id': range(1461,2920), 'SalePrice': final_labels}).to_csv('pred_EnsembleAvereging.csv', index =False)  \n",
    "\n",
    "print(\"Finished\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
