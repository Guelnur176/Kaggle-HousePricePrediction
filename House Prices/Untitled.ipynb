{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n",
      "(1447, 65)\n",
      "(1459, 64)\n",
      "New shape train: (1447, 206)\n",
      "Indice da coluna SalePrice no novo dataset 196\n",
      "New shape test: (1459, 208)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def remove_categorical_columns(df):\n",
    "    df.drop('MSZoning',axis=1,inplace=True)\n",
    "    df.drop('Street',axis=1,inplace=True)\n",
    "    df.drop('Alley',axis=1,inplace=True)\n",
    "    df.drop('LotShape',axis=1,inplace=True)\n",
    "    df.drop('LandContour',axis=1,inplace=True)\n",
    "    df.drop('Utilities',axis=1,inplace=True)\n",
    "    df.drop('LotConfig',axis=1,inplace=True)\n",
    "    df.drop('LandSlope',axis=1,inplace=True)\n",
    "    df.drop('Neighborhood',axis=1,inplace=True)\n",
    "    df.drop('Condition1',axis=1,inplace=True)\n",
    "    df.drop('Condition2',axis=1,inplace=True)\n",
    "    df.drop('BldgType',axis=1,inplace=True)\n",
    "    df.drop('HouseStyle',axis=1,inplace=True)\n",
    "    df.drop('RoofStyle',axis=1,inplace=True)\n",
    "    df.drop('RoofMatl',axis=1,inplace=True)\n",
    "    df.drop('Exterior1st',axis=1,inplace=True)\n",
    "    df.drop('Exterior2nd',axis=1,inplace=True)\n",
    "    df.drop('MasVnrType',axis=1,inplace=True)\n",
    "    df.drop('ExterQual',axis=1,inplace=True)\n",
    "    df.drop('ExterCond',axis=1,inplace=True)\n",
    "    df.drop('Foundation',axis=1,inplace=True)\n",
    "    df.drop('BsmtQual',axis=1,inplace=True)\n",
    "    df.drop('BsmtCond',axis=1,inplace=True)\n",
    "    df.drop('BsmtExposure',axis=1,inplace=True)\n",
    "    df.drop('BsmtFinType1',axis=1,inplace=True)\n",
    "    df.drop('BsmtFinType2',axis=1,inplace=True)\n",
    "    df.drop('Heating',axis=1,inplace=True)\n",
    "    df.drop('HeatingQC',axis=1,inplace=True)\n",
    "    df.drop('CentralAir',axis=1,inplace=True)\n",
    "    df.drop('Electrical',axis=1,inplace=True)\n",
    "    df.drop('KitchenQual',axis=1,inplace=True)\n",
    "    df.drop('Functional',axis=1,inplace=True)\n",
    "    df.drop('FireplaceQu',axis=1,inplace=True)\n",
    "    df.drop('GarageType',axis=1,inplace=True)\n",
    "    df.drop('GarageFinish',axis=1,inplace=True)\n",
    "    df.drop('GarageQual',axis=1,inplace=True)\n",
    "    df.drop('GarageCond',axis=1,inplace=True)\n",
    "    df.drop('PavedDrive',axis=1,inplace=True)\n",
    "    df.drop('PoolQC',axis=1,inplace=True)\n",
    "    df.drop('Fence',axis=1,inplace=True)\n",
    "    df.drop('MiscFeature',axis=1,inplace=True)\n",
    "    df.drop('SaleType',axis=1,inplace=True)\n",
    "    df.drop('SaleCondition',axis=1,inplace=True)\n",
    "\n",
    "def input_missing_value(df):\n",
    "    \n",
    "    \n",
    "    #LotFrontage - insert the mean \n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=1)\n",
    "    #print(np.shape(df['LotFrontage']))\n",
    "    df['LotFrontage'] = imp.fit_transform(df['LotFrontage']).transpose()    \n",
    "   \n",
    "    #Alley\n",
    "    df.Alley.fillna(inplace=True,value='No')\n",
    "\n",
    "    #MasVnrType - remove the records where the value is NA\n",
    "    #print(\"Number of lines where MasVnrType has Nan value\", len(df[df['MasVnrType'].isnull()]))\n",
    "    #df.dropna(axis=0,subset=['MasVnrType'],inplace=True)\n",
    "    #print(\"Number of lines where MasVnrType has Nan value\",len(df[df['MasVnrType'].isnull()]))\n",
    "    df.drop('MasVnrType',axis=1,inplace=True)\n",
    "    \n",
    "    #MasVnrArea - remove the hole column\n",
    "    df.drop('MasVnrArea',axis=1,inplace=True)\n",
    "    \n",
    "    #Condition2 - remove the hole column Possui quantidade de tipos diferentes na base de treino e teste e apenas \n",
    "    #um dos tipos é relevante    \n",
    "    df.drop('Condition2',axis=1,inplace=True)\n",
    "    \n",
    "    #RoofMatl - remove the hole column Possui quantidade de tipos diferentes na base de treino e teste e apenas \n",
    "    #um dos tipos é relevante    \n",
    "    df.drop('RoofMatl',axis=1,inplace=True)\n",
    "    \n",
    "\n",
    "    #MSZoning   - tem NA apenas na base de teste. Como nao posso remover linhas removo a coluna   \n",
    "    #df.dropna(axis=0,subset=['MSZoning'],inplace=True)\n",
    "    df.drop('MSZoning',axis=1,inplace=True)\n",
    "    \n",
    "    #BsmtQual\n",
    "    df.BsmtQual.fillna(inplace=True,value='No')\n",
    "    \n",
    "    #HouseStyle - Esse valor so existe na base de treino. Ao inves de remover toda coluna removo somente as linhas \n",
    "    df.drop(df[df.HouseStyle=='2.5Fin'].index,inplace=True)\n",
    "    \n",
    "    #BsmtCond\n",
    "    df.BsmtCond.fillna(inplace=True,value='No')\n",
    "\n",
    "    #BsmtExposure\n",
    "    df.BsmtExposure.fillna(inplace=True,value='No')\n",
    "\n",
    "    #BsmtFinType1\n",
    "    df.BsmtFinType1.fillna(inplace=True,value='No')\n",
    "\n",
    "    #BsmtFinType2\n",
    "    df.BsmtFinType2.fillna(inplace=True,value='No')\n",
    "\n",
    "    #Electrical - remove the records where the value is NA\n",
    "    #print(\"Number of lines where Electrical has Nan value\",len(df[df['Electrical'].isnull()]))\n",
    "    df.dropna(axis=0,subset=['Electrical'],inplace=True)\n",
    "    df.drop(df[df.Electrical=='Mix'].index,inplace=True)\n",
    "    #print(\"Number of lines where Electrical has Nan value\",len(df[df['Electrical'].isnull()]))\n",
    "\n",
    "    #FireplaceQu\n",
    "    df.FireplaceQu.fillna(inplace=True,value='No')\n",
    "    \n",
    "\n",
    "    #GarageType\n",
    "    df.GarageType.fillna(inplace=True,value='No')\n",
    "\n",
    "    #GarageYrBlt - remove the hole column\n",
    "    df.drop('GarageYrBlt',axis=1,inplace=True)\n",
    "\n",
    "    #GarageFinish\n",
    "    df.GarageFinish.fillna(inplace=True,value='No')\n",
    "\n",
    "    #GarageQual - A base de teste nao tem um dos tipos presente na base de treino. Assim a base de treino terá uma \n",
    "    #feature para esse tipo e a de teste não. Alem disso, apenas um tipo é pertinente\n",
    "    #Achei melhor entao excluir essa coluna    \n",
    "    df.drop('GarageQual',axis=1,inplace=True)\n",
    "    #df.drop(df[df.GarageQual=='Ex'].index,inplace=True)\n",
    "    \n",
    "    #GarageCond\n",
    "    df.GarageCond.fillna(inplace=True,value='No')\n",
    "\n",
    "    #PoolQC\n",
    "    #df.PoolQC.fillna(inplace=True,value='No')\n",
    "    df.drop('PoolQC',axis=1,inplace=True)\n",
    "    \n",
    "    #Fence\n",
    "    df.Fence.fillna(inplace=True,value='No')\n",
    "\n",
    "    #MiscFeature\n",
    "    #df.MiscFeature.fillna(inplace=True,value='No')\n",
    "    df.drop('MiscFeature',axis=1,inplace=True)\n",
    "\n",
    "    #MiscVal\n",
    "    df.drop('MiscVal',axis=1,inplace=True)\n",
    "    \n",
    "    #SaleType\n",
    "    df.drop('SaleType',axis=1,inplace=True)\n",
    "    \n",
    "    #Exterior1st- nao posso remover linhas do teste\n",
    "    #df.dropna(axis=0,subset=['Exterior1st'],inplace=True)     \n",
    "    #df.drop(df[df.Exterior1st=='Stone'].index,inplace=True)\n",
    "    #df.drop(df[df.Exterior1st=='ImStucc'].index,inplace=True)\n",
    "    #df.drop(df[df.Exterior1st=='CBlock'].index,inplace=True)\n",
    "    df.drop('Exterior1st',axis=1,inplace=True)\n",
    "    \n",
    "    #Exterior2nd\n",
    "    #df.dropna(axis=0,subset=['Exterior2nd'],inplace=True)\n",
    "    #df.Exterior2nd.fillna(inplace=True,value= 'Other')\n",
    "    #df.drop(df[df.Exterior2nd=='Other'].index,inplace=True)\n",
    "    #df.drop(df[df.Exterior2nd=='CBlock'].index,inplace=True)\n",
    "    df.drop('Exterior2nd',axis=1,inplace=True)\n",
    "    \n",
    "    #Heating -- esses tipos existem apenas na base de treino\n",
    "    df.drop(df[df.Heating=='OthW'].index,inplace=True)\n",
    "    df.drop(df[df.Heating=='Floor'].index,inplace=True)\n",
    "    \n",
    "    #KitchenQual\n",
    "    #df.dropna(axis=0,subset=['KitchenQual'],inplace=True)\n",
    "    df.KitchenQual.fillna(inplace=True,value='Po')\n",
    "    \n",
    "    #Functional\n",
    "    #df.dropna(axis=0,subset=['Functional'],inplace=True)\n",
    "    df.drop('Functional',axis=1,inplace=True)\n",
    "    \n",
    "    #Utilities\n",
    "    df.drop('Utilities',axis=1,inplace=True)\n",
    "    \n",
    "    #BsmtFinSF1\n",
    "    #df.dropna(axis=0,subset=['BsmtFinSF1'],inplace=True)\n",
    "    df['BsmtFinSF1'] = imp.fit_transform(df['BsmtFinSF1']).transpose()    \n",
    "    \n",
    "    #BsmtFinSF2\n",
    "    #df.dropna(axis=0,subset=['BsmtFinSF2'],inplace=True)\n",
    "    df['BsmtFinSF2'] = imp.fit_transform(df['BsmtFinSF2']).transpose()    \n",
    "    \n",
    "    #BsmtUnfSF\n",
    "    #df.dropna(axis=0,subset=['BsmtUnfSF'],inplace=True)\n",
    "    df.drop('BsmtUnfSF',axis=1,inplace=True)\n",
    "    \n",
    "    #TotalBsmtSF\n",
    "    #df.dropna(axis=0,subset=['TotalBsmtSF'],inplace=True)\n",
    "    df['TotalBsmtSF'] = imp.fit_transform(df['TotalBsmtSF']).transpose()    \n",
    "    \n",
    "    #BsmtFullBath - apenas na base de teste tem NA.Nao posso remover a linha\n",
    "    df.BsmtFullBath.fillna(inplace=True,value='0')\n",
    "    \n",
    "    #BsmtHalfBath- apenas na base de teste tem NA.Nao posso remover a linha\n",
    "    df.BsmtHalfBath.fillna(inplace=True,value='0')\n",
    "    \n",
    "    #GarageCars\n",
    "    #df.dropna(axis=0,subset=['GarageCars'],inplace=True)\n",
    "    df.GarageCars.fillna(value='0',inplace=True)\n",
    "    \n",
    "    #GarageArea\n",
    "    #df.dropna(axis=0,subset=['GarageArea'],inplace=True)\n",
    "    df.GarageArea.fillna(value='0',inplace=True)\n",
    "    \n",
    "df = pd.read_csv(\"train.csv\",na_values=['?','NA'],delimiter=',',delim_whitespace=False)\n",
    "df_test = pd.read_csv(\"test.csv\",na_values=['?','NA'],delimiter=',',delim_whitespace=False)\n",
    "\n",
    "print(df.shape)\n",
    "print(df_test.shape)\n",
    "#print(df.head())\n",
    "#print(df.describe)\n",
    "#print(df.dtypes)\n",
    "#df = df.dropna()\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "########################Dealing with missing values\n",
    "\n",
    "#missing data\n",
    "# total = df.isnull().sum().sort_values(ascending=False)\n",
    "# percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "# missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "# print(missing_data.head(20))\n",
    "\n",
    "# \n",
    "#               Total   Percent\n",
    "# PoolQC         1453  0.995205\n",
    "# MiscFeature    1406  0.963014\n",
    "# Alley          1369  0.937671\n",
    "# Fence          1179  0.807534\n",
    "# FireplaceQu     690  0.472603\n",
    "# LotFrontage     259  0.177397\n",
    "# GarageCond       81  0.055479\n",
    "# GarageType       81  0.055479\n",
    "# GarageYrBlt      81  0.055479\n",
    "# GarageFinish     81  0.055479\n",
    "# GarageQual       81  0.055479\n",
    "# BsmtExposure     38  0.026027\n",
    "# BsmtFinType2     38  0.026027\n",
    "# BsmtFinType1     37  0.025342\n",
    "# BsmtCond         37  0.025342\n",
    "# BsmtQual         37  0.025342\n",
    "# MasVnrArea        8  0.005479\n",
    "# MasVnrType        8  0.005479\n",
    "# Electrical        1  0.000685\n",
    "# Utilities         0  0.000000\n",
    "\n",
    "\n",
    "\n",
    "#print(df.columns[df.isnull().any()])\n",
    "#'LotFrontage', 'Alley', 'MasVnrType', 'MasVnrArea', 'BsmtQual',\n",
    "#       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "#       'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
    "#       'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence',\n",
    "#       'MiscFeature'\n",
    "input_missing_value(df)\n",
    "\n",
    "\n",
    "#print(df_test.columns[df_test.isnull().any()])\n",
    "#Index(['MSZoning', 'LotFrontage', 'Alley', 'Utilities', 'Exterior1st',\n",
    "#       'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond',\n",
    "#       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
    "#      'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n",
    "#       'BsmtHalfBath', 'KitchenQual', 'Functional', 'FireplaceQu',\n",
    "#      'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea',\n",
    "#       'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature',\n",
    "#       'SaleType'],\n",
    "\n",
    "input_missing_value(df_test)\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "########################End dealing with missing values\n",
    "\n",
    "\n",
    "# The OneHotEncoder converts features represented as numeric codes (so they are values that can't be ordered) to their binary representation\n",
    "#enc = preprocessing.OneHotEncoder() \n",
    "#aux = enc.fit_transform(data_train)\n",
    "\n",
    "\n",
    "########################Tratando campos nominais\n",
    "\n",
    "vec = DictVectorizer()\n",
    "aux = np.asmatrix(vec.fit_transform(df.transpose().to_dict().values()).toarray())\n",
    "\n",
    "data_train = pd.DataFrame(aux,columns=vec.feature_names_)\n",
    "#data_train = pd.get_dummies(df)\n",
    "\n",
    "\n",
    "data_train.to_csv('train_no_categorical.csv')\n",
    "\n",
    "print(\"New shape train:\" , np.shape(data_train))\n",
    "print(\"Indice da coluna SalePrice no novo dataset\" , data_train.columns.get_loc('SalePrice'))\n",
    "\n",
    "################################################# Base de teste\n",
    "\n",
    "\n",
    "aux_test = vec.fit_transform(df_test.transpose().to_dict().values()).toarray()\n",
    "data_test = pd.DataFrame(aux_test,columns=vec.feature_names_)\n",
    "#data_test = pd.get_dummies(df_test)\n",
    " \n",
    "print(\"New shape test:\" , np.shape(data_test))\n",
    "\n",
    "data_test.to_csv('test_no_categorical.csv')\n",
    "\n",
    "\n",
    "#print(data_test.columns.difference(data_train.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      1434.000000\n",
      "mean     180426.479777\n",
      "std       78962.777094\n",
      "min       34900.000000\n",
      "25%      130000.000000\n",
      "50%      162000.000000\n",
      "75%      213500.000000\n",
      "max      755000.000000\n",
      "Name: SalePrice, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAPUCAYAAAAwlzp0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f804984e2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAFoCAYAAACFXfuDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUqUMI5IkqVKGEUmSVKn/H/1EZw2bkOE+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8049918438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAFoCAYAAAAVToJMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f804b29d978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "print(df.SalePrice.describe())\n",
    "\n",
    "saleprice_scaled = preprocessing.StandardScaler().fit_transform((df['SalePrice'][:,np.newaxis]));\n",
    "fig = plt.figure(1, figsize=(6, 12))\n",
    "#ax = fig.add_subplot(111)\n",
    "#ax.boxplot(saleprice_scaled)\n",
    "plt.boxplot(saleprice_scaled)\n",
    "\n",
    "plt.figure()\n",
    "x = plt.hist(df['SalePrice'],bins=50)\n",
    "\n",
    "plt.figure()\n",
    "saleprice_log = np.log(df['SalePrice'])\n",
    "x = plt.hist(saleprice_log,bins=50)\n",
    "\n",
    "#df['SalePrice'] = np.log(df['SalePrice'])\n",
    "#df_test['SalePrice'] = np.log(df_test['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tentativa de selecionar melhores features \n",
      "\n",
      "As features selecionadas com Tree-based feature selection foram: \n",
      "\n",
      "['ExterQual=TA' 'GarageCars' 'BsmtQual=Ex' 'GrLivArea' 'OverallQual'\n",
      " 'FullBath' 'Neighborhood=NoRidge' 'FireplaceQu=No' '1stFlrSF' '2ndFlrSF'\n",
      " 'TotalBsmtSF' 'TotRmsAbvGrd' 'GarageArea' 'BsmtFinSF1' 'ExterQual=Fa'\n",
      " 'YearBuilt' 'BsmtFinType1=GLQ' 'BsmtExposure=Gd' 'KitchenQual=Ex'\n",
      " 'BedroomAbvGr' 'YearRemodAdd' 'GarageType=Attchd' 'LotArea' 'BsmtFullBath'\n",
      " 'LandSlope=Gtl']\n",
      "[[ 0.2835539   0.11809401  0.11217612  0.0693582   0.06251442  0.03953778\n",
      "   0.02497636  0.02034298  0.01715109  0.01270132  0.01174466  0.01058595\n",
      "   0.00957348  0.00759987  0.00753727  0.00736904  0.00707669  0.00687793\n",
      "   0.00634909  0.00526895  0.00513499  0.00507242  0.00490453  0.00480355\n",
      "   0.00473018]]\n",
      "\n",
      " New shape train apos Tree-based feature selection: (1447, 25)\n",
      "\n",
      " Fim tentativa selecionar melhores features \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-438-77a7160a44b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mdata_test_less_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n New shape test apos Tree-based feature selection: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/christian/anaconda3/lib/python3.5/site-packages/sklearn/feature_selection/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0minput\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mselected\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/christian/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/christian/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "print(\"\\n Tentativa de selecionar melhores features \\n\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "#Removing features with low variance\n",
    "#print(\"Original shape: {}\".format(np.shape(df.iloc[:,0:-1])))\n",
    "#sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "#features = sel.fit_transform(df.iloc[:,0:-1])\n",
    "#print(\"Shape apos Removing features with low variance {}\".format(np.shape(features))) #nenhuma foi selecionada \n",
    "#print(\"\\n\")\n",
    "\n",
    "#Tree-based feature selection\n",
    "y_train = (data_train['SalePrice'])\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "\n",
    "clf = ExtraTreesRegressor()\n",
    "clf = clf.fit(x_train,y_train)\n",
    "data = np.zeros((1,x_train.shape[1])) \n",
    "data = pd.DataFrame(data, columns=x_train.columns)\n",
    "data.iloc[0] = clf.feature_importances_\n",
    "data = data.T.sort_values(df.index[0], ascending=False).T\n",
    "\n",
    "\n",
    "print(\"As features selecionadas com Tree-based feature selection foram: \\n\")\n",
    "yyy = np.asarray((data.columns[0:25]))\n",
    "xxx = np.asarray((data.iloc[:,0:25]))\n",
    "print(yyy)\n",
    "print(xxx)\n",
    "\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "aux = model.transform(x_train)\n",
    "\n",
    "print(\"\\n New shape train apos Tree-based feature selection: {}\".format(aux.shape))\n",
    "\n",
    "print(\"\\n Fim tentativa selecionar melhores features \\n\")\n",
    "\n",
    "\n",
    "data_train_less_features = pd.concat([pd.DataFrame(aux),pd.DataFrame(y_train)],axis=1)\n",
    "data_train_less_features.to_csv('data_train_less_features.csv')\n",
    "\n",
    "\n",
    "aux = model.transform((data_test))\n",
    "data_test_less_features = pd.DataFrame(aux)\n",
    "print(\"\\n New shape test apos Tree-based feature selection: {}\".format(aux.shape))\n",
    "data_test_less_features.to_csv('data_test_less_features.csv')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn   import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso 1 - Linear Regression \n",
      "Fold #1\n",
      "Fold score (RMSE): 8354563543231763.00\n",
      "Accuracy: -12458030138837715386368.000\n",
      "Fold #2\n",
      "Fold score (RMSE): 158460584181134752.00\n",
      "Accuracy: -3726408452776093298982912.000\n",
      "Fold #3\n",
      "Fold score (RMSE): 113731207645894576.00\n",
      "Accuracy: -1763348002058255906897920.000\n",
      "Fold #4\n",
      "Fold score (RMSE): 31231.60\n",
      "Accuracy: 0.837\n",
      "Fold #5\n",
      "Fold score (RMSE): 332493846203527872.00\n",
      "Accuracy: -20338904494499399144046592.000\n",
      "\n",
      " Average RMSE: 1.7226996583672058e+17\n",
      "\n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 25467.75\n",
      "Accuracy: 0.878\n",
      "Fold #2\n",
      "Fold score (RMSE): 33399.67\n",
      "Accuracy: 0.828\n",
      "Fold #3\n",
      "Fold score (RMSE): 34529.32\n",
      "Accuracy: 0.844\n",
      "Fold #4\n",
      "Fold score (RMSE): 26829.83\n",
      "Accuracy: 0.861\n",
      "Fold #5\n",
      "Fold score (RMSE): 45436.46\n",
      "Accuracy: 0.681\n",
      "\n",
      " Average RMSE: 33874.87199962136\n"
     ]
    }
   ],
   "source": [
    "#Starting making predictors\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Caso 1 - Linear Regression \n",
    "print(\"Caso 1 - Linear Regression \")\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#Normalization\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = LinearRegression()\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# The mean squared error\n",
    "#pred = classifier.predict(x_test_scaled)\n",
    "#score = metrics.mean_squared_error(y_test, pred)\n",
    "#print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "\n",
    "# Evaluate success using accuracy\n",
    "#print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "\n",
    "\n",
    "###########Less features\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "#Normalization\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = LinearRegression()\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Fold #1\n",
      "Fold score (RMSE): 74847.85\n",
      "Accuracy: -0.060\n",
      "Fold #2\n",
      "Fold score (RMSE): 77168.45\n",
      "Accuracy: -0.086\n",
      "Fold #3\n",
      "Fold score (RMSE): 85039.21\n",
      "Accuracy: -0.033\n",
      "Fold #4\n",
      "Fold score (RMSE): 84686.21\n",
      "Accuracy: -0.048\n",
      "Fold #5\n",
      "Fold score (RMSE): 82757.60\n",
      "Accuracy: -0.048\n",
      "\n",
      " Average RMSE: 81004.21189731291\n",
      "\n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 75665.57\n",
      "Accuracy: -0.081\n",
      "Fold #2\n",
      "Fold score (RMSE): 83078.72\n",
      "Accuracy: -0.062\n",
      "Fold #3\n",
      "Fold score (RMSE): 89938.57\n",
      "Accuracy: -0.061\n",
      "Fold #4\n",
      "Fold score (RMSE): 72267.24\n",
      "Accuracy: -0.011\n",
      "Fold #5\n",
      "Fold score (RMSE): 83082.02\n",
      "Accuracy: -0.067\n",
      "\n",
      " Average RMSE: 81043.57829131559\n"
     ]
    }
   ],
   "source": [
    "#Caso 3 - SVM\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "print(\"SVM\")\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#Normalization\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = SVR()\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# The mean squared error\n",
    "#pred = classifier.predict(x_test_scaled)\n",
    "#score = metrics.mean_squared_error(y_test, pred)\n",
    "#print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "\n",
    "# Evaluate success using accuracy\n",
    "#print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "###########Less features\n",
    "print(\"\\n\\n\")\n",
    "#Normalization\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = SVR()\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN MLPRegressor\n",
      "Fold #1\n",
      "Fold score (RMSE): 48186.30\n",
      "Accuracy: 0.692\n",
      "Fold #2\n",
      "Fold score (RMSE): 37578.04\n",
      "Accuracy: 0.780\n",
      "Fold #3\n",
      "Fold score (RMSE): 34465.42\n",
      "Accuracy: 0.807\n",
      "Fold #4\n",
      "Fold score (RMSE): 41785.84\n",
      "Accuracy: 0.689\n",
      "Fold #5\n",
      "Fold score (RMSE): 92689.10\n",
      "Accuracy: -0.647\n",
      "\n",
      " Average RMSE: 55208.522690122765\n",
      "\n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 30178.77\n",
      "Accuracy: 0.828\n",
      "Fold #2\n",
      "Fold score (RMSE): 38604.46\n",
      "Accuracy: 0.771\n",
      "Fold #3\n",
      "Fold score (RMSE): 44195.03\n",
      "Accuracy: 0.744\n",
      "Fold #4\n",
      "Fold score (RMSE): 26000.48\n",
      "Accuracy: 0.869\n",
      "Fold #5\n",
      "Fold score (RMSE): 50946.15\n",
      "Accuracy: 0.599\n",
      "\n",
      " Average RMSE: 39043.73564618396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Shuffle\n",
    "print(\"NN MLPRegressor\")\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "#Normalization\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10,4,2), random_state=1)\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# The mean squared error\n",
    "#pred = classifier.predict(x_test_scaled)\n",
    "#score = metrics.mean_squared_error(y_test, pred)\n",
    "#print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "\n",
    "# Evaluate success using accuracy\n",
    "#print(\"Final Accuracy: %.3f\" % classifier.score(X=x_test_scaled,y=y_test))\n",
    "\n",
    "###########Less features\n",
    "print(\"\\n\\n\")\n",
    "#Normalization\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "scaler = preprocessing.StandardScaler().fit((x_train))\n",
    "x_train_scaled = scaler.transform((x_train))\n",
    "\n",
    "\n",
    "classifier = MLPRegressor(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(8,2), random_state=1)\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train_scaled):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train_scaled[training]\n",
    "    y_train_fold = y_train[training]\n",
    "    x_test_fold = x_train_scaled[test]\n",
    "    y_test_fold = y_train[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): %.2f\" %(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests\n",
      "Mean squared error: 22551.009437553967\n",
      "Accuracy: 0.880\n",
      "\n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 26138.671898927667\n",
      "Accuracy: 0.898\n",
      "Fold #2\n",
      "Fold score (RMSE): 29058.523655909987\n",
      "Accuracy: 0.873\n",
      "Fold #3\n",
      "Fold score (RMSE): 33920.823932803854\n",
      "Accuracy: 0.817\n",
      "Fold #4\n",
      "Fold score (RMSE): 34302.14523960701\n",
      "Accuracy: 0.804\n",
      "Fold #5\n",
      "Fold score (RMSE): 29454.415223354128\n",
      "Accuracy: 0.840\n",
      "\n",
      " Average RMSE: 30733.42881260155\n",
      "\n",
      "\n",
      "\n",
      "Mean squared error: 33095.847125220906\n",
      "Accuracy: 0.847\n",
      "\n",
      "\n",
      "\n",
      "Fold #1\n",
      "Fold score (RMSE): 28439.45557962573\n",
      "Accuracy: 0.847\n",
      "Fold #2\n",
      "Fold score (RMSE): 34996.57400160665\n",
      "Accuracy: 0.812\n",
      "Fold #3\n",
      "Fold score (RMSE): 30571.05908482807\n",
      "Accuracy: 0.877\n",
      "Fold #4\n",
      "Fold score (RMSE): 26008.211122792934\n",
      "Accuracy: 0.869\n",
      "Fold #5\n",
      "Fold score (RMSE): 33373.59757674328\n",
      "Accuracy: 0.828\n",
      "\n",
      " Average RMSE: 30847.40268543391\n"
     ]
    }
   ],
   "source": [
    "##Random Forests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Shuffle\n",
    "print(\"Random Forests\")\n",
    "np.random.seed(42)\n",
    "data_train = data_train.reindex(np.random.permutation(data_train.index))\n",
    "data_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_train.drop('SalePrice',axis=1), data_train['SalePrice'], test_size=0.20, random_state=42)\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test,y=y_test))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "y_train = ((data_train['SalePrice']))\n",
    "x_train = (data_train.drop('SalePrice',axis=1))\n",
    "\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train.as_matrix()[training]\n",
    "    y_train_fold = y_train.as_matrix()[training]\n",
    "    x_test_fold = x_train.as_matrix()[test]\n",
    "    y_test_fold = y_train.as_matrix()[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "\n",
    "###########Less features\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Split into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_train_less_features.drop('SalePrice',axis=1), \n",
    "                                    data_train_less_features['SalePrice'], test_size=0.20, random_state=42)\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# The mean squared error\n",
    "pred = classifier.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(\"Mean squared error: {}\".format(score))\n",
    "# Evaluate success using accuracy\n",
    "print(\"Accuracy: %.3f\" % classifier.score(X=x_test,y=y_test))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "y_train = ((data_train_less_features['SalePrice']))\n",
    "x_train = (data_train_less_features.drop('SalePrice',axis=1))\n",
    "\n",
    "\n",
    "classifier = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "kf = KFold(5)    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for training, test in kf.split(x_train):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train_fold = x_train.as_matrix()[training]\n",
    "    y_train_fold = y_train.as_matrix()[training]\n",
    "    x_test_fold = x_train.as_matrix()[test]\n",
    "    y_test_fold = y_train.as_matrix()[test]\n",
    "    \n",
    "    classifier.fit(x_train_fold, y_train_fold)\n",
    "    pred = classifier.predict(x_test_fold)\n",
    "    oos_y.append(y_test_fold)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure accuracy    \n",
    "    score = np.sqrt(metrics.mean_squared_error(y_test_fold,pred))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "    # Evaluate success using accuracy\n",
    "    print(\"Accuracy: %.3f\" % classifier.score(X=x_test_fold,y=y_test_fold))\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_y,oos_pred))\n",
    "print(\"\\n Average RMSE: {}\".format(score))    \n",
    "\n",
    "# Write the cross-validated prediction\n",
    "\n",
    "pred = classifier.predict(np.asmatrix(data_test_less_features))\n",
    "result = pd.DataFrame(pred,columns=['SalePrice'])\n",
    "\n",
    "result.to_csv('pred_RF.csv', sep=',')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
